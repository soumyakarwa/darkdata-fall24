{
  "zine": {
    "name": "Dark Data",
    "issue": "Fall 2024",
    "publication_date": "2024-12-07",
    "categories": {
      "digital-misogyny": {
        "id": "digital-misogyny",
        "section-title": "Digital Misogyny",
        "articles": [
          {
            "id": "neven-armanios-rodriguez-title-tbd",
            "title": "THE PROBLEM WITH INCOMPLETE DATA",
            "subtitle": "The Data that Misinforms and only Scratches the Surface",
            "author": {
              "name": "NEVEN ARMANIOS",
              "email": "ashrf576@newschool.edu",
              "bio": ""
            },
            "content": {
              "body": "With every New Year approaching, I prepare to make new year’s resolutions, and there is always one resolution that I strive to fulfill — losing weight. This year, as we reach the end of 2024, I will probably make the same resolution. But, in 2025, this resolution will not involve intermittent fasting. I tried that already. It did not work. In the past, whenever I repeatedly tried not eating for a good part of the morning and early afternoon, my efforts to lose weight came up short. Why? I discovered that women do not benefit from intermittent fasting in the same way that men do. Turns out that the data historically praising the results of intermittent fasting relied on aggregated data - data where the majority if not all of the subjects were male. One of the first clinical studies to investigate intermittent fasting was done on men, published in the Journal of Nutrition, Health, and Aging, in 2013 (Hussin et al). The study had a total of 32 healthy males aged around 59.7±6.3 years. No women were included in this preliminary study.<br><br>It was actually my female general practitioner who pointed out that my efforts with intermittent fasting might be futile. I learned from her that the data that was available to me during my attempts to fast intermittently was likely lacking and misleading. From what I read online, I assumed that the benefits of fasting would be experienced by most if not all who changed their dietary consumption timeframe. A study by Alum at al found that “Intermittent fasting is a beneficial concept for increasing the quality of life, for weight loss, for metabolism, and even for increasing the lifespan. However, the impact is considered to be different in men and women, for example, in hormonal shifts, alterations in body composition, energy levels, and the reproductive system” (Alum et al). When women are much more vulnerable to hormonal imbalance than men, they often don't see the same results as men with intermittent fasting. Studies examining intermittent fasting effects on women are limited and additional studies are required to gain knowledge that highlights the distinctions between the sexes.<br><br>In fact, I have noticed that on many issues, the data on women is either missing or incomplete. Therefore, I am sharing instances where I, as a woman, was affected by the shortage of information, and that’s how I noticed this shortage of female-centric data. If we look at issues that are less personal to me and more global, such as climate change, again we observe that the data collected on women falls short.<br><br>The state of the planet was different in the 2000s, or at least not as seriously in peril as it is today. However, if in 2008, when I was pregnant with my son, if the climate was anything like what we are dealing with in 2024, I may have faced serious vulnerabilities as a pregnant woman. Interested in the impacts of climate change on  women specifically, I searched for data. I learned that climate change poses risks to pregnant women in particular. Not only does global warming affect women differently than it affects men, it affects pregnant women, and their unborn babies, differently than non-pregnant women. For instance, according to the United States Environmental Protection Agency, 1 out of 10 infants born in 2019 in the United States were born preterm (before 37 weeks of pregnancy completed) due to a mother's exposure to extreme heat (EPA). And studies suggest climate change affects women both in wealthier nations and in poorer countries.<br><br>In less developed countries, climate-related destructive patterns, including extreme heat, flooding, and wildfires, have been linked to pregnancy-related health problems such as low birth weight, preterm birth, and even miscarriage. This data is not widely accessible and, sadly, not enough research has been done on this topic.<br><br>Women also face another issue in many countries where water is scarce. With 1.8 billion people living in households without water supplies on the premises, women and girls aged 15 and older are primarily responsible for water collection in 7 out of 10 such households (UNICEF).  After a drought or natural disaster due to climate change, these same women and girls must travel longer and further to find water, at times placing themselves in danger. Yet, studies conducted on the impacts of climate change do not deaggregate the data to provide insights needed to see how one gender is exponentially affected more so than another gender. Nor are there enough efforts made to collect data about women affected by global warming. This lack of data can create doubts about whether women are truly affected differently, in this case, by climate change.<br><br>You may be questioning this hypothesis yourself. It was definitely controversial amongst my friends and at my university when I started to discuss it. Some people were surprised and questioned this hypothesis. Why? — because there has not been enough of a focus by practitioners in the field of global warming to collect more specific data. Whether one agrees that women face different risks because of climate change than men is not the issue. The issue is that the data we do have scratches the surface. The challenge to collect gender-specific data is ubiquitous due to cultural norms and privacy issues. However, protecting an individual's privacy while gaining data necessary for accurate insight is possible. Rather than ignoring a particular demographic completely by aggregating the data, disaggregating the data is needed. Research topics, where consequential data collection is necessary, requires inclusivity and the active account of different populations. In the example of climate change and women, we do not have enough data to understand thoroughly what women and girls have to contend with, and this is a problem.<br><br>Data can also be unreliable for a number of reasons, even when it is technically accurate. This was the case with intermittent fasting for me. The same can be seen with research conducted on artificial sweeteners that often fail to account for critical factors that could clarify the true health impacts. People typically turn to nonsugar sweeteners after developing health issues like diabetes or weight gain, leading to a misconception that these sweeteners do not worsen the very problems they were intended to help manage. Many studies rely on self-reported consumption data, which is unreliable, because sweeteners are often hidden in ingredient lists. This is just one other found example that has been recorded. Many examples are non-existent because researchers have not focused enough on collecting targeted, comparative data. It’s simply missing.<br><br>Efforts are being made to raise awareness around gaps in data collection. For instance, Mimi Onuoha, a Nigerian-American artist, shows the contradictions between the advancement of technology and the obscurity of accurate data. Through her installations, she draws attention to missing data: information that is absent. In her project titled “The Library of Missing Datasets” (Figure 1-2), we observe file cabinets with labeled folders, which are empty. For instance, the folder labeled “Number of Americans without bank accounts in 2008,” is empty. What does that suggest? It suggests that even though this is an existing issue, since there is no data collected on it, it is easy to overlook and to consider it non-existent and not important (Onuoha).<br><br><div class=image-container><img src=\"/images/NEVEN_IMAGE1.jpg\"><p class=caption>Fig. 1. Mimi Onuoha. “The Library of Missing Datasets.” 2018.</p><img src=\"/images/NEVEN_IMAGE2.jpg\"><p class=caption>Fig. 2. Mimi Onuoha. “The Library of Missing Datasets.” 2018.</p></div><br><br>Onuoha also explicitly states that Black people are both “over-collected” and “under-represented” with data. What she means by that is that the lack of data about Black populations is a significant issue; comprehensive and detailed data regarding demographics, health issues, socioeconomic status, and other key aspects of life are often missing or insufficient. This absence of data makes it difficult to accurately understand and address disparities faced. Factors such as historical underrepresentation in research studies, data collection limitations, and mistrust within the community towards research initiatives are to blame.<br><br>Due to systemic racism, the exclusion of Black people from research studies limits the data available on health and social experiences. The data, at times, is aggregated, masking important variables, and in turn, makes it difficult to identify specific needs. For instance, studies like the Tuskegee Syphilis Study (CDC) have created a deep distrust among African Americans towards medical research, leading to lower participation rates in studies.<br><br>Without accurate data, policymakers will struggle to design effective programs that address the specific needs of African Americans while researchers and physicians will not be able to effectively treat their health. For example, when it comes to cancer research, African Americans “make up about 14% of the U.S. population but only 5% to 7% of clinical trial participants. Clinical trial participation is important because it provides people with the opportunity to access new cancer treatments, tests, and approaches to improving cancer care” (Jaber). All too often, African Americans are not adequately represented in research studies because their data was never collected and analyzed.<br><br>As both my personal experiences and these studies highlight, data collection can go wrong due to a lack of data, misleading data, or inaccurate data. Disaggregated data is often not available because it doesn’t get collected. Sadly, as we’ve seen, datasets often only scratch the surface of an issue and could be described as incomplete, misleading or inaccurate.<br><br>",
              "works-cited": [
                "Alum, Esther Ugo, Emmanuel Ifeanyi Obeagu, Okechukwu Paul-Chima Ugwu, Benedict Nnachi Alum, Echegu Darlington Arinze1, Chris U. A. Ukaidi. “Exploring the Differential Impacts of Intermittent Fasting on Men and Women.” Elite Journal of Health",
                "Sciences. Volume 2, Issue 5, 2024, pp.  37-44. https://www.researchgate.net/publication/381740409_Differential_Impacts_of_Intermittent_Fasting_on_Men_and_Women",
                "CDC. “About The Untreated Syphilis Study at Tuskegee.” https://www.cdc.gov/tuskegee/about/index.html ",
                "EPA. “Climate Change and the Health of Pregnant, Breastfeeding, and Postpartum Women.” United States Environmental Protection Agency website. https://www.epa.gov/climateimpacts/climate-change-and-health-pregnant-breastfeeding-and-postpartum-women.",
                "Jaber, Nadia. “How Do Black People with Cancer View Clinical Research?” November 15, 2024. National Cancer Institute. https://www.cancer.gov/news-events/cancer-currents-blog/2024/black-patients-beliefs-clinical-medical-research",
                "Hussin, N. M., S. Shahar, N. I. M. F. Tang, W. Z. W. Ngah, S. K. Das. “Efficacy of fasting and calorie restriction (FCR) on mood and depression among ageing men.” The Journal of Nutrition, Health, and Aging. 17 (8), 2013, pp. 674-80. https://pubmed.ncbi.nlm.nih.gov/24097021/",
                "Onuoha, Mimi. “The Library of Missing Datasets.” https://mimionuoha.com/the-library-of-missing-datasets-v-20.",
                "Unicef. “Women and girls bear brunt of water and sanitation crisis.” UNICEF-WHO report. 5 July 2023. https://www.unicef.org/press-releases/women-and-girls-bear-brunt-water-and-sanitation-crisis-new-unicef-who-report"
              ],
              "images": [
                {
                  "url": "/images/NEVEN_FINAL.png",
                  "caption": "An illustrative image",
                  "alt_text": "Image showing zine artwork"
                }
              ]
            }
          },
          {
            "id": "xiangying-fang-title-tba",
            "title": "FEMININITY IN SERVICE AI",
            "subtitle": "The Digital Reinscription of Gendered Emotional Labor",
            "author": {
              "name": "XIANGYING FANG",
              "email": "fangx339@newschool.edu",
              "bio": ""
            },
            "content": {
              "body": "Service AI systems like Alexa and Siri have become central to daily life, assisting with tasks from setting reminders to providing information. Yet, while these tools represent technological advancements, they also mirror and reinforce gender stereotypes, especially around labor.<br><br>It strikes me how service AIs reinforce traditional gender roles, embodying femininity in subservient, \"helpful\" capacities. These systems, by defaulting to female voices and a deferential persona, perpetuate outdated norms of politeness and compliance. Why do we find it \"natural\" for these supportive roles to be filled by a feminine voice that remains calm, polite, and accepting regardless of treatment?<br><br>In this article, I aim to unpack the layers of cultural, social, and design choices contributing to this trend, examining how these biases are reinforced—and how they might be addressed, and propose inclusive redesigns for service AI to model healthier, boundary-respecting interactions.<h3>The Feminization of Service AI: A Legacy of Gender Norms</h3>From the outset, tech companies anthropomorphized digital assistants with female voices, names, and personalities, aligning with longstanding gender norms where women are expected to be supportive and nurturing. This feminization feels \"natural\" because of embedded cultural associations: women, often cast in administrative or caregiving roles, are perceived as approachable and sympathetic.<br><br>The first notable instance of  digital female assistant voices voices being deliberately used in digital technologies dates back to the mid-20th century with the development of automated systems like Bell Labs’ Voder in the 1930s and 1940s. While the Voder was a general speech synthesis machine, early applications of synthesized speech often featured feminine tones due to perceptions that women’s voices were more pleasant and reassuring for users. This trend continued with the rise of IVR (Interactive Voice Response) systems in the 1970s and 1980s, where female voices became the norm for automated call centers, aligning with stereotypes of women as caretakers and communicators​<br><br>These norms are deeply rooted in Western and global perceptions of gender. For instance, Amazon's Alexa and Apple's Siri were designed with female voices because user testing revealed people responded better to these tones, which were seen as more \"supportive\" and \"trustworthy\".​ Research supports these choices. Studies, like those by Nass et al., show that users respond favorably to female-voiced assistants, associating them with helpfulness and supportiveness, which are culturally aligned with stereotypical feminine traits. Despite AI’s neutrality, users anthropomorphize it, projecting their biases and casting it into roles of emotional labor.<br><br>This emotional labor is reinforced as female-presenting AIs often respond politely, even in the face of rudeness. By engineering subservient female voices into AI, designers perpetuate the expectation that women, like AI, should absorb frustration without pushing back—reflecting real-world biases.<h3>Passive Politeness: The Enforcement of Submissive Communication</h3>A key aspect of feminized service AI is its consistent politeness, even in response to hostility. This deferential style, especially when assigned to a feminine voice, reinforces societal expectations for women to communicate with restraint and avoid confrontation.<br><br>Consider common interactions with these assistants. Commands are met with cheerful responses like “Certainly!” or “How can I help?” even if the user’s tone is curt or disrespectful. Siri and Alexa remain polite and accommodating, enforcing “digital passive aggression” by requiring politeness even in the face of disrespect. Digital assistants like Alexa often respond politely, even in disrespectful situations. An example includes Alexa replying with \"I’m sorry, I didn’t catch that\" when a user makes rude or sarcastic comments. This programming reinforces the expectation that the assistant—and by extension, women—should remain subservient and accommodating regardless of tone​. This non-assertive style reinforces real-world expectations, where women are socialized to communicate agreeably.<br><br>Feminized AI’s polite responses reinforce the stereotype of women as naturally agreeable. Studies, like Abercrombie et al.’s Alexa, Google, Siri: What Are Your Pronouns?, show people generally respond to female voices in AI as they would to women, expecting sensitivity and “soft” communication. Such expectations risk shaping user perceptions of real-world interactions with women.<br><br>Psychological studies have supported these observations. For instance, research on user interactions with voice-based AI reveals a preference for female voices in non-stressful or emotionally engaging tasks, reinforcing the stereotype that women are better suited for nurturing or supportive roles. Conversely, male voices tend to be preferred in high-pressure scenarios, reflecting a bias associating men with authority and technical proficiency. Humans are prone to treating computers as social actors, . They perform experiments showing that people apply social rules to their interactions with computers, such as engaging in behaviors that they would typically reserve for human social interactions like politeness, compliance, and deference, that they would typically reserve for human social interactions. For example, people often respond more positively to AIa voices that areis calm and polite, assuming the AI is \"friendly\" or \"helpful,\" even if it's just programmed to respond in certain ways.<h3>Digital Emotional Labor: AI as a Virtual Caregiver</h3>A striking feature of feminized AI is its role in emotional labor, much like women in caregiving roles. Female-voiced AIs “manage” users’ emotions, responding sympathetically or humorously to rude remarks, reflecting societal expectations that women absorb negativity while maintaining harmony.<br><br>For instance, Alexa has programmed responses to flirtatious or sexist comments, often deflecting with humor. This design mirrors real-world norms that women should deflect inappropriate behavior while maintaining composure. Thus, feminized AI is expected not only to perform tasks but to manage social dynamics, keeping interactions smooth and conflict-free.<br><br>The UNESCO report I'd Blush if I Could addresses this dynamic, noting how AI design reinforces gender norms by assigning emotional labor to female voices. When female-voiced AI responds non-confrontationally to negative comments, it mirrors the societal expectation for women to avoid conflict and passively absorb emotional burdens. In embedding these traits, tech companies endorse gendered expectations, reinforcing emotional labor as intrinsic to femininity.<h3>Social Consequences: Reinforcing Gendered Expectations in Real Life</h3>The feminization of emotional labor in AI doesn’t exist in isolation; it influences user perceptions and potentially how they interact with real women. By interacting with AI that exhibits “ideal” feminine traits—politeness, emotional resilience, and availability—users may begin expecting similar behavior from women they encounter. Feminized AI thus risks setting restrictive standards, subtly suggesting women should embody resilience, politeness, and support.<br><br>Sociological studies have examined this spillover effect. For instance, Robertson’s The Female Persona in AI explores how feminized AI subtly encourages users to treat AI—and by extension, women—as subservient. These implications are significant: as feminized AI becomes embedded in daily life, it risks perpetuating biases that affect real-world social norms.<br><br>Further, female-voiced AI rarely displays assertiveness or boundaries. This cultural expectation that women remain supportive and agreeable, especially in service roles, becomes a default assumption users may apply outside digital contexts. Feminized AI could thus reinforce restrictive gender roles in real-world interactions.<h3>Redesigning Service AI: Toward Inclusive Solutions</h3>To counteract these biases, AI design must be inclusive, offering options that defy gender norms. Non-binary or gender-neutral voices, like the Q – The Genderless Voice Assistant, challenge binary gender norms, offering users choices beyond traditional masculine or feminine voices.<br><br>Rethinking emotional labor in AI could also lead to progress. Instead of programming AI with stereotypically “feminine” responses, developers might try assertive responses that model healthier boundaries. For example, rather than deflecting inappropriate comments with humor, AI could respond with neutrality or direct redirection, reducing the risk of reinforcing submissive expectations. These design changes would promote fairer, more realistic portrayals of service roles and gender.<br><br>Additionally, transparency in AI development can help users understand how design choices affect interactions. When users recognize that politeness and emotional labor are designed traits—not intrinsic qualities of “feminine” AI—they may become more aware of their biases. I'd Blush if I Could advocate for such transparency, suggesting that informed users are better positioned to question embedded stereotypes.<h3>In Conclusion: Toward Balanced, Unbiased AI</h3>As I delve into the dynamics of feminized service AI, it becomes clear this isn’t merely about convenience. It’s a reflection of how we view gendered labor and identity. Service AIs like Alexa and Siri, designed with feminine, subservient traits, mirror societal expectations that women should handle emotional labor, remain pleasant, and manage discomfort.<br><br>By designing AI to embody passivity and emotional labor, tech companies unintentionally reinforce gender stereotypes, influencing user expectations in digital and real-life interactions. Addressing these issues is essential for creating fairer AI and challenging restrictive gender norms affecting women on a broader scale.<br><br>The future of AI lies in inclusive, thoughtful design—one that values diversity and encourages users to question their own biases. By offering gender-neutral options, creating assertive response protocols, and promoting transparency, the tech industry can lead the way in redefining AI’s relationship to gender. As we reimagine AI free from restrictive gender expectations, we open the door to a more equitable digital world where every user feels represented and respected.<br><br>",
              "works-cited": [
                "West, M., Kraut, R., & Chew, H. E. (2019). I'd Blush if I Could: Closing Gender Divides in Digital Skills Through Education. UNESCO. Available at: UNESCO Digital Library.",
                "Costa, P., & Ribas, L. (2019). AI Becomes Her: Discussing Gender and Artificial Intelligence. Technoetic Arts, 17(2), 151-161. DOI: 10.1386/tear_00014_1.",
                "Abercrombie, G., Cercas Curry, A., Pandya, M., & Rieser, V. (2021). Alexa, Google, Siri: What Are Your Pronouns? Gender and Anthropomorphism in the Design and Perception of Conversational Assistants. arXiv preprint. Available at: arXiv.",
                "Vice Media Group. Q – The Genderless Voice Assistant. Copenhagen Pride. Available at: Genderless Voice.",
                "Nass, C., & Brave, S. (2005). Wired for Speech: How Voice Activates and Advances the Human-Computer Relationship. The MIT Press.",
                "Rossen, J. (2020). \"Why Do Virtual Assistants Like Siri and Alexa Traditionally Have Female Voices?\" Mental Floss, 9 May 2020, https://www.mentalfloss.com/article/624227/why-do-virtual-assistants-siri-and-alexa-traditionally-have-female-voices."
              ],
              "images": [
                {
                  "url": "/images/XIANGYING_FINAL.png",
                  "caption": "An illustrative image",
                  "alt_text": "Image showing zine artwork"
                }
              ]
            }
          },
          {
            "id": "amy-lewis-title-tba",
            "title": "A DEEP DIVE INTO DEEPFAKES",
            "author": {
              "name": "AMY LEWIS",
              "email": "lewia046@newschool.edu",
              "bio": ""
            },
            "content": {
              "body": "2024 has been the year of Charlie XCX’s “Brat summer”, the WNBA breaking records in viewership for women’s sports, and of course, the U.S. nominating its first black female presidential candidate Kamala Harris. Technology and online spaces were crucial to the participation in these defining moments of history and pop culture. Following the trend of recent years, 2024 had an increased online presence and was plagued with disinformation. There are a number of caveats to why these online spaces pose a threat to those who choose to engage. But is there really a choice? So much connectivity relies on online spaces that it’s hard to navigate life without it. For women in particular, the risk of being present online has shown to be an open door to threats against privacy, security, and autonomy. Enter: the deepfake.<br><br>Developing in the 1990s into the 2010s, CGI technology morphed from swapping out some special effects into mimicking real life movement and sound. The idea of creating ultra realistic images using 3D effects and simulations is nothing new but in 2014, this technology took a turn<sup>1</sup>. Ian Goodfellow is credited specifically in a long list of computer scientists who introduced new machine learning technology and “deep learning” that transformed image, video, and audio to what we know today<sup>2</sup>. Of course, the spread of this technology didn’t happen overnight and was refined and perfected by the average internet user. With platforms like Reddit, it became easier to crowdsource machine learning tools and utilize it along with imagery already posted publicly to create manipulated explicit content to circulate by anonymous perpetrators. In 2018, Vice posted an article about discovering a “deleted subreddit appropriately named r/deepfakes [that] had nearly 91,000 members and featured deepfake porn from a variety of actors”<sup>3</sup>. Reddit banned the account and updated their privacy policy which influenced some other major tech platforms to do the same.<br><br>Since 2019, there has been a granular response from news outlets, companies, and governments on how more protections need to be put into place particularly with the rise of targeting everyday women. A study by Security Hero found in 2023 that deepfake pornography takes up 98% of all deepfake videos online and creating a 60 second deepfake video costs $0, only needs one clear face image, and takes less than 25 minutes<sup>4</sup>. A major factor in deepfake pornography getting out of control is the reliance of victims reporting the content to tech platforms, then those same platforms having little to no point of contact for requests to take content down. These tech platforms are complicit in allowing the continuation of ravaging a woman's personal and professional life without repercussions.<br><br>To uncover more of how deepfakes have spread and what governments are doing now, Columbia University PhD candidate Kaylee Williams who is an expert in technology-facilitated gender-based violence, gave some insight about what deepfakes are and how the U.S. is currently battling this issue in the justice system. The language surrounding deepfake technology is hard to decipher and so even defining the term is complicated. Ms. Williams notes that “there’s a lot of debate right now around what kind of language makes most sense to use around this kind of media. Mostly these days, I’m using the phrase that a lot of advocates use like ‘deepfake abuse’...There are many survivors and victim advocates that want to keep the word pornography out of it because it has many salacious aspects to it. The broadest definition is going to be sexually explicit visual media, which is generated or manipulated using artificial intelligence tools or machine learning, created or distributed without consent of the subject it depicts.” With that, it’s no wonder people have a hard time understanding what deepfakes are and how to navigate the discourse surrounding this growing issue.<br><br>Currently in the U.S., there are no federal laws specifically combatting deepfakes, but President Biden pushed an executive order at the end of 2023 to “direct the Office of Management and Budget to consider the risks of deepfake image-based sexual abuse of adults and children in its forthcoming AI procurement guidance… to promote widespread adoption of industry standards to prevent AI systems from generating abuse material”<sup>5</sup>. Certain states have also made strides at the local government level to remedy the threat while conversations continue at the federal level. Each state is unique in how they have started to take action towards deepfakes so “there are massive inconsistencies in the way that different state legislators define the key terms involved in these issues…There is still not a law against non-consensual pornography (i.e. revenge porn) in general at the federal level so they are several steps behind”<sup>6</sup>. What’s troubling is that living in a certain area or if you are over the age of 18 means more or less protections against the same horrific crime.<br><br>Many states already have existing laws that cover child sexual abuse and child pornography. This allows for a segway into what could be more conversations around AI-generated content and deepfakes as each state starts to run into more cases that affect adult women. Ms. Williams keeps tabs on different state legislatures as this issue has slowly progressed in her research where “many states will add in a stipulation that criminalizes the deepfake if there was an intent to harm a person. This can be tricky because it opens the loophole to create a defense that [can be talked out of that intention]. We will see if that kind of language stands since so many of these laws have not been tested in court yet…Hopefully things like this would come out in discovery with any sort of threats or abusive messages as well as the content itself.” Oftentimes, victims find out about their likeness being used in a deepfake by receiving a direct message to it by someone else or even the creator themselves. What has made traction in courts is having many cases linked to minors with cyberbullying or cyberharassment where the states have been able to act faster in providing protections.<br><br>In January of this year, pornographic deepfake images were shared of Taylor Swift on X (formerly Twitter) that she had no consent or hand in creating. These images were shared and viewed millions of times before they were taken down from the platform. The course of action for X was to suspend the account that these images originated from and block the search for “Taylor Swift” for 24 hours. The head of operations at X, Joe Benarroch, said at the time these actions were “temporary” and treated with “an abundance of caution as we prioritize safety on this issue”<sup>7</sup> but no other follow up was done by X on who the account belonged to, how to prevent another attack, and ultimately was panned by Taylor Swift and her team to pursue legal action in court.<br><br>Other female public figures have been targets to pornographic deepfakes such as Addison Rae, who became the one of the most followed and influential stars on TikTok at only 19. With a simple google search, deepfake pornographic images of her are still circulating on different sites like Youtube, Pornhub, and websites selling her likeness to make more content. NBC reported an X account that posted a deepfake of Rae linked to a longer porn video with the creator “delete[ing] the tweet after receiving backlash and [X] did not respond to an emailed request for comment, which included links to nine accounts posting pornographic deepfakes. [X] later suspended six of those accounts”<sup>8</sup>. Even here, by a major news outlet the identity of these anonymous creators is more concealed than those who are victims.<br><br>Celebrities are subject to so much scrutiny while having the ability to ease out of the public eye, making it difficult to connect these instances to those of everyday women who may struggle with the same abuse. Garnering traction for women in our communities continues to be an uphill battle but “a lot of people became aware of this phenomenon for the first time when celebrities became victims of it like the Taylor Swift deepfake incident. It took it happening to Taylor Swift, the most popular pop star in the world, to see that this could be hurtful. There is a role for celebrities to play in saying that this is something that happened to me and I don’t like it, I have the means to address this that normal people don’t”<sup>9</sup>. Women being the target of these attacks at an astronomically high level brings questions of what can they do to protect themselves and promote awareness of this issue?<br><br>More women shouldn’t have to endure abuse before pornographic deepfakes get the attention of law officials and the public at large. The message here is not for women to go totally offline and be made to not trust the internet or their communities, but more as a proceed with caution. Ms. Williams provided some advice that shines hope from what is currently circulating on the internet as follows:<br><br><div class=\"image-container\"><div class=quote>“Get familiar with what these local laws are within your state or local county, so that if your images get used in a non-censual way you know exactly who to contact.”</div><div class=quote>“Document everything and the communication you receive about the abuse itself. A lot of the time people will get a mysterious message saying your pictures are on this website… so just keeping a good archive of what happened is going to be key.”</div><div class=quote>“Any kind of sexual abuse is going to inspire feelings of shame and embarrassment, it will be really hard but it’s really important to be willing to advocate for yourself in those moments.”</div></div><br><br>It is important to share this information while the U.S. and other countries still uncover the intricacies of deepfakes and the dark spaces they tend to stick to in the lawless webbing of online platforms.<br><br>Women shouldn’t have to have a different set of rules when it comes to engaging in online spaces nor should they fear their privacy may be violated. It is critical that those who are most vulnerable take steps within their power to fight back. Non-consensual pornographic deepfakes “are another manifestation of an age-old problem which is actually one of misogyny. Until we as a society and culture address the root causes of this problem there will continue to be new manifestations of [it]… criminalizing the kind of content is not going to address the sort of societal norms and trends that created these problems in the first place”<sup>10</sup>. The misogynistic ideals that are emboldened by the use of deepfakes are threatening strides in women’s rights in the digital age. Let the conversation and collective action continue as we look ahead to 2025.<h3>Further readings by Kaylee Williams, Tech Policy Press</h3>Kaylee Williams is a PhD student at the Columbia Journalism School and a research associate at the International Center for Journalists. Her research specializes in technology-facilitated gender-based violence, with a particular emphasis on generative AI and non-consensual intimate imagery. Prior to her doctoral studies, she was a research fellow at Harvard University's Shorenstein Center for Media, Politics & Public Policy, where she investigated coordinated disinformation and cyberharassment campaigns. When time permits, she also covers tech policy and social media platforms as a freelance journalist. She holds a Master of Arts in Political Science from Columbia University.<ul><li><a href=\"https://www.techpolicy.press/minors-are-on-the-frontlines-of-the-sexual-deepfake-epidemic-heres-why-thats-a-problem/Minors\">Are On the Frontlines of the Sexual Deepfake Epidemic — Here’s Why That’s a Problem | TechPolicy.Press</a></li><li><a href=\"https://www.techpolicy.press/tightening-restrictions-on-deepfake-porn-what-us-lawmakers-could-learn-from-the-uk/\">Tightening Restrictions on Deepfake Porn: What US Lawmakers Could Learn from the UK | TechPolicy.Press</a></li><li><a href=\"https://www.techpolicy.press/poll-vast-majority-of-us-voters-agree-individuals-and-platforms-should-be-held-accountable-for-sexually-explicit-digital-forgeries/\">Poll: Vast Majority of US Voters Agree Individuals and Platforms Should be Held Accountable for Sexually Explicit Digital Forgeries | TechPolicy.Press</a></li></ul>",
              "works-cited": [
                " Regan, Gabe. “A Brief History of Deepfakes - Reality Defender.” Reality Defender, 2024.",
                "Goodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. “Proceedings of the International Conference on Neural Information Processing Systems (NIPS 2014).” Montreal: University of Montreal, 2013.",
                "Kelion, Leo. “Reddit Bans Deepfake Porn Videos.” BBC News, February 7, 2018.",
                " Security Hero. “2023 State of Deepfakes.” 2023 State Of Deepfakes: Realities, Threats, And Impact, 2023.",
                "Morgan, Lucy. “It’s Not Just Taylor Swift-All Women Are at Risk from the Rise of Deepfakes.” Glamour, February 1, 2024.",
                "Williams, Kaylee. Interview by author Amy Lewis and editor Katya Danziger. New York City, November 22, 2024.",
                "Morgan, Lucy. “It’s Not Just Taylor Swift-All Women Are at Risk from the Rise of Deepfakes.” Glamour, February 1, 2024.",
                " Tenbarge, Kat. “Deepfake Porn of Tiktok Stars Thrives on Twitter.” NBCNews.com, June 12, 2023.",
                "Williams, Kaylee. Interview by author Amy Lewis and editor Katya Danziger. New York City, November 22, 2024.",
                "Williams, Kaylee. Interview by author Amy Lewis and editor Katya Danziger. New York City, November 22, 2024."
              ],
              "images": [
                {
                  "url": "/images/AMY_FINAL.png",
                  "caption": "An illustrative image",
                  "alt_text": "Image showing zine artwork"
                }
              ]
            }
          }
        ]
      },
      "surveillance-and-the-media": {
        "id": "surveillance-and-the-media",
        "section-title": "Surveillance & The Media",
        "articles": [
          {
            "id": "viviane-ma-title-tba",
            "category": "Surveillance & The Media",
            "title": "THE CULTURE GAP ON SOCIAL MEDIA",
            "author": {
              "name": "VIVIANE-YUERONG MA",
              "email": "may770@newschool.edu",
              "bio": ""
            },
            "content": {
              "body": "How often do you come across reposted content on social media that are from another country? Do you ever look at the comment section, trying to find someone who answers your question or holds the same opinion as you? Whether it is X (Twitter), Instagram, TikTok, or any other platforms, social media is so efficient at delivering unlimited and even ‘exotic’ contents to your devices.<h3>Those That Catch the Viewers’ Eyes</h3>Being a social media influencer seems to be one of the easiest ways to grow your own career in today’s time. There is almost no budget required to start your own account, and unlike some countries that may require you to upload proofs of your identity, you can simply register on most sites in the United States with a click of a button, or several buttons at most. Growing up as a Gen Z, influencers also made up many of my fellow classmates’ conversations in high school. You do not need to go fish for the news on Google, TikTok will bring you the hottest trends and controversies after a few swips. In October 2021, confidential data on Twitch streamers’ salaries leaked online, exposing the payouts received by some of the biggest streamers on the internet. The popular Dungeons and Drangons channel, CriticalRole, earned $9,626,712.16 from August 2019 to October 2021; and individual streamers like xQcOW earned up to $8,454,427.17 with that time span. With that much profit, it is with no doubt that youngsters may lean towards a path within the industry of social media. But what does it take to shine through so many ‘wannabes’? To do things completely out of your comfort zone and pull on stunts for the views, maybe.<br><br>Mukbang, a popular live genre which usually involves the streamer to consume various quantities of food, became popular in the 2010s. From eating while chatting with viewers, it soon became sensational - to stand out from thousands of Mukbangs, you either eat more, or eat weird. There are obviously critics that comes with the fame. Food waste and fake eating were the main problems. It got to a point where the Chinese video streaming site, Bilibili, starts showing “eat responsibly” when viewers search for videos containing the word “Chi Bo” (Mukbang in Chinese) or “Da Wei Wang” (People who are able to eat large quantities of food). Today, the trend of Mukbang has gone out of sight, but there is still a constant fan base, and to achieve success through eating, you have to go even more extreme.<br><br>As a daily scroller myself, I often find myself in a loophole of strange videos on Instagram of people consuming non-edible looking foods, and a lot of times, it is by someone who is Chinese. These videos are reposted by attention farming accounts for the pure purpose of getting views and followers. Frankly, since hashtagging is a main portion of incoming views, it does not matter if the original video is actually from China or Korea, or other places, because the people will believe what they see. It is also important to note, that a lot of these videos are considered to be strange, even to Asians, and is a unrealistic capture of the lifestyle of Asian people. With different cultural backgrounds, viral videos usually get many backlashes, from the looks of the foods, to the way people consume them. This is not limited to Mukbang, and it is not limited to Western social media.<h3>Pro-Western and Anti-Western</h3>As I became more involved with my own cultural background, I found myself suck in a middleground, belonging to neither the western nor the Chinese community in the way I thought I would fit in.<br><br>The Little Red Book (Xiao Hong Shu) is a Chinese social media platform that is a mixture of Pinterest and Instagram, not only in its functionality, but also the contents within. Going back to our topic of Mukbang, as the Asian originated genre became viral internationally, many western creators have also picked up the gist and started their own version of the eating show. Similar to the the small portion of Asian Mukbang that received hate from other communities, attention farming accounts in China have also reposted videos from the Western media, usually the extreme ones that clearly is a portrayal of a minor community and shows vast differences from the Asian culture, for the purpose of raising arguments between Asian and Western communities.<br><br>One of the viral accounts on the Little Red Book is famous for reposting videos from an Instagram account named mamaj.rae, which is a mom posting daily meal preparation videos of a lower middle class family with seven kids. On the reposter’s profile biography, they claim to be a repost account for western food culture, sharing delicious food videos to others. With a total of 26.1k followers, the account only reposts mamaj.rae’s videos after finding initial success in July 2024, and each post has around 1000 likes, with the most popular video having 27.1k likes. The purpose of the account might be for entertainment only, but in a country with such massive population as China, it is hard for everyone to be at the same level of education, and definitely have not everyone been to foreign countries. With that being said, many comments are targeting the way the food is being cooked, whether the vegetables have been washed properly, or doubting the stereotypes of western culture that have been ingrained in Asian countries.<div class=\"image-container\"><img src=\"/images/VIVIANE_IMAGE1.jpg\"/></div>Of course, the food section of social media is not the only problematic part, but it shows how miss-information can be spread so easily using social media. Despite China blocking western media to prevent harmful government activities, most citizens do have ways around it, using VPNs to access the world outside of China. With that being said, people can definitely search up the truth and learn more about other cultures. Although, even though it is hard to admit, the pride within individuals are prone to keep the truth out, making absurd assumptions to be more believable. However, as the younger generations, it is our responsibility to be more mindful and patient with the information we intake, to differenciate the entertainment and the credible.<br><br>",
              "images": [
                {
                  "url": "/images/VIVIANE_FINAL.png",
                  "caption": "An illustrative image",
                  "alt_text": "Image showing zine artwork"
                }
              ]
            }
          },
          {
            "id": "nathan-williams-title-tba",
            "category": "Surveillance & The Media",
            "title": "SELF-EXPOSURE",
            "author": {
              "name": "NATHAN WILLIAMS",
              "email": "willr520@newschool.edu",
              "bio": ""
            },
            "content": {
              "body": "<div class=image-container><div class=quote>“The transformation of the television into a low-end computer monitor, or to inverse the terms; the portable computer into a video monitor, effectively transforms a personal, domestic device into an apparatus of behavior control, a post allowing us to see, in the very same moment, whatever is happening around the globe. But there is a price, which is to agree in return (in a counter-image) to be ourselves visually controlled, and now not only by institutions specializing in investigation, whether police or military surveillance, but by anybody and everybody<sup>1</sup>.”</div></div><br><br>Images have historically been the primary sources that we look to in order to find understanding and meaning behind human experience. We believe them to be truthful and reliable ways to represent certain aspects of our nature and, through our understanding of them, create a more certain and confident self. Defined as “a reproduction or imitation of the form of a person or thing”, an image encapsulates how information is received, processed, and recorded by human beings.<sup>2</sup> As Baudrillard claims, “Thus perhaps at stake has always been the murderous capacity of images: murderers of the real; murderers of their own model as the Byzantine icons could murder the divine identity.”<sup>3</sup><br><br>In our contemporary age of information overload, it is obvious that images are not as truthful and reliable as we have seemed to believe in the past, especially with new and emerging technologies like AI image making models and machine learning networks that can generate accurate deep fakes. These technologies allow a level of accessibility to image sources that we have never seen before, in which information surrounding an image can be found at the click of a button. Although we have become used to this capability in our age of information overload, what we have yet to understand or really bring attention to is how humans have shifted from becoming image consumers to image purveyors. According to a 2024 Pew Research Study on American’s Social Media Usage, 68% of U.S. Adults use Facebook, 47% use Instagram, and 33% use Tik Tok.<sup>4</sup> These platforms emphasize content creation, resulting in a meteoric rise of personal visual contributions. Although users are not forced to post on these platforms, without image purveyors, there would be no appeal. If images are becoming less trustworthy, more accessible, and easier to create and distribute on an individual level, the way that we understand ourselves through them will likely change too.<br><br><div class=image-container><div class=quote>Images have changed from existing as references we observe to becoming vehicles of validation that we craft,  shaping our  self-image and understanding of identity.</div></div><br><br>Surveillance technologies serve as a medium to craft our understanding of identity through personal image creation. Features like the camera, GPS, and microphone work together, allowing us to develop a curated image that we project into the world. Through this process of seeking self-understanding, the image validates us. Although it is important to note that surveillance technologies can be used for malicious purposes, they also hold an important and inarguable role in shaping the way that users of digital platforms perceive themselves, whether good or bad. A “more nuanced and productive portrait of this transition than doomsday scenarios offer” is needed, and if “this architecture truly breaks with Foucaldian discipline, we could justly wonder whether it should still be characterized as panoptic.”<sup>5</sup> Should we condemn this panoptic age outright if so many of us utilize surveillance technologies to relate to, validate, inform, and respond to others in order to better understand our place in the world? <br><br>Exhibitionist art offers a way to explore how a shift from image consumerism to image purveyance through the use of surveillance technologies has allowed people to explore  personal identity. For instance, Jill Magid’s “Evidence Locker” explores the process of receiving one’s image through a surveillance technology that is held by an enforcing power, which she then edits and stages. Through developing a relationship between herself and the enforcing power, she uncovers how she is perceived in public space as well as through the lens of a surveillance power.<sup>6</sup>Similarly, <a href=\"https://momus.ca/artists-in-isolation-wafaa-bilals-domestic-tension/\">Wafa Bilaal’s “Domestic Tension” explores how broadcasting and viewership influence behavior, especially when it comes to the identity of the surveyed.</a><sup>7</sup> Viewers hidden behind a camera have the ability to control his experience, serving as a metaphor to the treatment of Iraqi Americans in Post-9/11 America. Furthermore, Jennifer Wringley’s “Jennicam” was a pioneering experiment which dubbed her the first “camgirl,”sparking outrage surrounding exhibitionism and online presence.<sup>8</sup> These artworks have brought about interesting concepts, particularly that of “disruptive exhibitionism”, which “offers a way for marginalized identities and bodies to engage with visibility, where public visibility may be difficult or even dangerous.”<sup>9</sup> Engaging with exhibitionist artworks can reveal the intentions and revelations that individuals experience when interacting with surveillance technologies, particularly when it comes to the exploration of their own identity. These engagements are important in navigating and understanding our current state, where these technologies are the way in which we understand how to exist and perceive the world around us.<br><br>",
              "works-cited": [
                "Paul Virilio, “The Visual Crash,” in Ctrl [Space] : Rhetorics of Surveillance From Bentham to Big Brother, ed. Thomas Y. Levin, Ursula Frohne, and Peter Weibel (The MIT Press, 2002), 110.",
                "Merriam-Webster.com Dictionary, s.v. “image,” accessed December 10, 2024, https://www.merriam-webster.com/dictionary/image.",
                "Jean Baudrillard, Simulacra and Simulation, Trans. Sheila Faria Glaser (Ann Arbor: University of Michigan Press, 1994), 170.",
                "Jeffrey Gottfried, “Americans’ Social Media Use,” Pew Research Center, January 31, 2024, https://www.pewresearch.org/internet/2024/01/31/americans-social-media-use/.",
                "Julie Levin Russo, \"Show Me Yours: Cyber-Exhibitionism from Perversion to Politics,\" Camera Obscura 25, no. 1 (2010): 136, Durham: Duke University Press.",
                "Jill Magid, “Evidence Locker,” Jill Magid, accessed December 12, 2024, https://www.jillmagid.com/projects/evidence-locker-2.",
                "Rahel Aima, “Artists in Isolation: Wafaa Bilal’s ‘Domestic Tension,’” Momus, April 14, 2020, https://momus.ca/artists-in-isolation-wafaa-bilals-domestic-tension/.",
                "“Jennicam: The First Woman to Stream Her Life on the Internet.” BBC News, October 18, 2016. https://www.bbc.com/news/magazine-37681006.",
                "Julia Chan and Stéfy McKnight, “Disruptive Exhibitionism - a Performance Methodology for Surveillance Art,” Media Practice and Education 24, no. 2 (2023): 162, Routledge."
              ],
              "images": [
                {
                  "url": "/images/NATHAN_FINAL.png",
                  "caption": "An illustrative image",
                  "alt_text": "Image showing zine artwork"
                }
              ]
            }
          },
          {
            "id": "fatima-ashraf-title-tba",
            "category": "Surveillance & The Media",
            "title": "FROM GOD TO ALGORITHMS",
            "author": {
              "name": "FATIMA ASHRAF",
              "email": "ashrf576@newschool.edu",
              "bio": ""
            },
            "content": {
              "body": "The concept of panopticism has evolved from Jeremy Bentham’s 18th-century prison design to a broader framework that governs modern behavior. Bentham’s Panopticon, a circular prison with a central tower for guards to observe inmates without being seen, was revolutionary in its ability to maintain order through the perception of constant surveillance. Michel Foucault expanded this idea, suggesting that the panoptic structure was not limited to physical spaces but extended into society at large. He argued that modern institutions, from schools to workplaces, employ similar mechanisms to discipline individuals, making them internalize the gaze of authority. This internalization ensures compliance, not through physical enforcement but by cultivating the belief that one’s actions are always being watched and judged. This psychological effect has parallels in religious traditions that emphasize the omnipresence of a Divine Being.<br><br>Religious teachings across cultures reinforce the notion of an unseen observer, shaping moral and ethical conduct. Christianity, for instance, portrays God as an omniscient and omnipresent being, as reflected in Proverbs 15:3: “The eyes of the Lord are everywhere, keeping watch on the wicked and the good.” Similarly, in Islam, the Quran frequently describes Allah as “Al-Baseer,” the All-Seeing, observing every action and thought. These religious frameworks establish an internalized discipline among believers, who modify their behavior to align with moral codes, fearing divine retribution or seeking reward in the afterlife. The parallels to Bentham’s Panopticon are striking—just as prisoners cannot see their observer but believe in their presence, adherents of religious faith accept the unseen gaze of God as a guiding force in their lives.<br><br>Modern digital surveillance extends this dynamic into the technological age, transforming the observer from a deity to an algorithm. Shoshana Zuboff’s analysis of surveillance capitalism highlights how corporations like Google, Facebook, and Amazon monetize personal data, creating systems that track and predict human behavior. This form of surveillance is often accepted because of the conveniences it offers, such as personalized recommendations and enhanced security. However, the psychological effect mirrors religious conditioning. For example, a 2021 Pew Research Center study revealed that 70% of Americans use social media platforms despite concerns about data privacy, indicating a trade-off between privacy and perceived benefits. Users often engage in self-censorship and meticulously curate their online personas, anticipating scrutiny from peers, employers, or unseen authorities. This behavior aligns with Sarah Kendzior’s findings that the anticipation of being watched leads individuals to act in ways they believe will be socially acceptable, much like religious adherents striving to meet moral expectations.<br><br>Governments and corporations have also adopted panoptic methods to maintain control and order. In China, the social credit system exemplifies the fusion of surveillance and societal regulation. This system monitors citizens’ behaviors, assigning scores that determine access to services, jobs, and even travel. A low score can result in severe penalties, effectively conditioning individuals to conform to state-sanctioned norms. Similarly, in Western democracies, revelations such as Edward Snowden’s disclosure of the NSA’s PRISM program have shown how governments use surveillance to monitor global communications. Despite public outcry, these programs persist, reflecting society’s ambivalence toward the trade-offs between privacy and security. A 2020 survey by Ipsos found that 58% of respondents across 28 countries supported government surveillance for counterterrorism efforts, even if it meant sacrificing some personal freedoms.<br><br>The private sector also plays a significant role in normalizing surveillance. Companies like Amazon have integrated panoptic principles into everyday life through products like Ring doorbell cameras. Marketed as tools for home security, these devices enable neighborhood-wide surveillance networks, turning ordinary citizens into watchers. This phenomenon not only reinforces the perception of constant observation but also cultivates a sense of safety, akin to the comfort derived from religious beliefs in a protective deity. A 2022 report by Deloitte found that 75% of consumers trust technology companies to handle their data responsibly, despite the prevalence of data breaches. This trust mirrors the faith many have in religious systems, even in the absence of tangible proof of their fairness.<br><br>The political implications of digital surveillance are profound, particularly in authoritarian regimes where it is used to suppress dissent. During the 2020 protests in Belarus, activists reported being identified and arrested through facial recognition technology, demonstrating how surveillance can stifle opposition. In democracies, the effects are subtler but equally significant. Social media platforms, equipped with sophisticated algorithms, can influence public opinion and behavior by amplifying certain narratives while suppressing others. This power to shape societal norms and expectations underscores the enduring relevance of panopticism as a tool for control.<br><br>Religious conditioning has eased society’s acceptance of modern surveillance, making the concept of being watched seem natural, even comforting. For centuries, belief systems have associated observation with order and morality, a framework that digital surveillance seamlessly integrates. Real-world surveys and studies reinforce this connection. For example, a 2023 study published in Computers in Human Behavior found that individuals who grew up with strong religious beliefs were more likely to accept surveillance technologies as beneficial. This finding suggests that the internalized discipline fostered by religious teachings carries over into the digital realm, where surveillance systems are perceived as necessary for maintaining societal order.<br><br>The parallels between religious and digital surveillance reveal a shared purpose: the regulation of behavior through observation. In both systems, the observer holds power by being invisible yet ever-present, creating a sense of accountability among those being watched. This dynamic has shaped human behavior for centuries and continues to evolve in  the digital age. While the tools and actors have changed, the underlying principles of panopticism remain constant, illustrating its enduring influence on society.<br><br><a href=\"https://editor.p5js.org/ashrf576/sketches/2tEAmlEkY\">p5.js Web Editor | eye</a>",
              "images": [
                {
                  "url": "/images/FATIMA_FINAL.png",
                  "caption": "An illustrative image",
                  "alt_text": "Image showing zine artwork"
                }
              ]
            }
          }
        ]
      },
      "hidden-narratives": {
        "id": "hidden-narratives",
        "section-title": "Hidden Narratives",
        "articles": [
          {
            "id": "nick-lyons-title-tba",
            "category": "Hidden Narratives",
            "title": "(UN)PROTECTED HEALTH INFORMATION",
            "author": {
              "name": "NICK LYONS",
              "email": "lyonn670@newschool.edu",
              "bio": ""
            },
            "content": {
              "body": "Digital health has become commonplace for many healthcare patients, from the daily use of fitness tracking devices to advanced health monitoring services from vendors like One Medical. While these advancements provide new and exciting experiences for patients, they can also open the door to data risks related to health information. For years, health information was protected by a federal regulation called the Health Insurance Portability and Accountability Act (HIPAA). These protections are being challenged by new risks that have emerged with digital health advancements.<h3>Covered Entities</h3>Even when HIPAA was passed in 1996, many healthcare providers did not qualify as covered entities due to the definition highlighted in the regulation. In order to be a covered entity, the provider must conduct electronic transfers as defined by the Department of Health and Human Services. For example, a public school that provides healthcare services only for students is not a HIPAA covered entity because student health information is classified as “education records.” This highlights a gap in current legislation that poses risks to the security of sensitive health information.<h3>Digital Devices</h3>People share sensitive data on digital devices to promote good health, but that data may be recorded and vulnerable. Some forms of data these devices and applications record include fingerprints used to unlock phones, face scans from facial recognition technology, fitness and fertility tracking information, mental health diagnoses, and digital medical records.Recording this data can provide valuable insights for consumers that enable new ways to stay healthy, but some of these digital device companies may be sharing that data with third-parties. The negative impacts of this data sharing could include raising insurance premiums, discriminating against applicants for jobs and housing, and even enabling surveillance.<h3>Health Data for Sale</h3>While many people may have some awareness of data exchange of some level, they also may assume that their sensitive health data is under some form of protection. Unfortunately, the various loopholes of data collection actually make it very possible, and even legal, for sensitive health data to be shared or sold through data brokers. As Deborah Serani, author of Living with Depression notes,<br><br><div class=image-container><div class=quote>“While this is quite alarming, all of this is legal and under the general public’s radar. It’s been happening for years and is a long-standing breach that places health information at risk.”<sup>1</sup><br><br></div></div>This information might include diagnoses like depression or prescribed medications, often with patient names and addresses. This gap in patient protections is not highly publicised, even though many regulatory organizations are aware that current laws are out of date and not comprehensive. The speed at which innovation changes the landscape will continue to challenge current legislation and practices. Consumers must advocate for responsive action from commercial and government interests in order to ensure meaningful protections.",
              "works-cited": [
                "Your Mental Health Data Is Being Sold—and It’s Legal.” 2023. Healthline. March 10, 2023. https://www.healthline.com/health-news/your-mental-health-data-is-being-sold-and-its-legal.",
                "Daniel, Lars. 2024. “100 Million Americans’ Medical Records Exposed in Massive Data Breach.” Forbes. October 28, 2024. https://www.forbes.com/sites/larsdaniel/2024/10/28/100-million-americans-medical-records-exposed-in-massive-data-breach/.",
                "Fry, Hannah. 2024. “Tracking Your Health with a Device? Here’s Where the Data Could Go.” Los Angeles Times. November 20, 2024. https://www.latimes.com/california/story/2024-11-20/how-much-does-your-smartwatch-know-about-you.",
                "HIPAA Journal. 2017. “What Are Covered Entities under HIPAA?” HIPAA Journal. October 18, 2017. https://www.hipaajournal.com/covered-entities-under-hipaa/.",
                "Seh, Adil Hussain, Mohammad Zarour, Mamdouh Alenezi, Amal Krishna Sarkar, Alka Agrawal, Rajeev Kumar, and Raees Ahmad Khan. 2020. “Healthcare Data Breaches: Insights and Implications.” Healthcare 8 (2): 133. https://doi.org/10.3390/healthcare8020133."
              ],
              "images": [
                {
                  "url": "/images/NICK_FINAL.png",
                  "caption": "An illustrative image",
                  "alt_text": "Image showing zine artwork"
                }
              ]
            }
          },
          {
            "id": "katya-danziger-title-tba",
            "category": "Hidden Narratives",
            "title": "SALVAGING OUR SHARED REALITY",
            "sub-title": "An Op-Ed About What’s at Stake & Where We’re Headed",
            "author": {
              "name": "KATYA DANZIGER",
              "email": "danzk958@newschool.edu",
              "bio": ""
            },
            "content": {
              "body": "<div class=image-container><div class=quote>“Polarization” is Merriam-Webster’s 2024 word of the year, which might be the one idea that both sides of the political spectrum can agree on.<sup>1</sup> Some might call it the word of the decade.<sup>2</sup> Media polarization by class and the attention economy have led us to this point.</div></div><br><br>As Machiavelli understood, the only way for the Prince to conquer self-governing states (i.e. democracies) was to reduce them to rubble.<sup>3</sup>We are currently experiencing a Machiavellian information age, undermined and eroded by Big Tech corporations that profit from distorting democracy and amplifying outrage. I believe that the massive global political disruptions we are experiencing aren't because of the pandemic, inflation, neoliberalism, or horse race journalism, but are the direct result of unchecked destructive social media algorithms that have killed trust in institutions and experts, and promoted loud ignorance and outrage everywhere.<br><br>In layman terms, social media users can see only a controlled fraction of what content is posted daily to their feeds. What they do see is highly curated by the platform’s automated systems designed to keep people glued to their smartphones. Using machine learning and so-called recommender systems<sup>4</sup>(collaborative and content-based filtering, see NVIDIA’s Glossary), these systems determine within milliseconds what content to display to social media users. This mechanism is what makes our public political discourse more and more extreme as the algorithm is trained to choose conflict and controversy, which light up the feed and attract likes in a way that subtlety and ambiguity never will. Big Tech favors extremism to boost engagement and thus profits. (A Science study published at the end of November 2024 found that social media posts containing misinformation evoke more moral outrage than posts with trustworthy information, and that outrage facilitates the spread of misinformation.<sup>5</sup>)<br><br>Journalism faces “extinction-level threats”<sup>6</sup> as monolithic and divisive “feeds” replace and defund traditional journalism. Alice Marwick warns that, “the gap between mainstream media readers, people who get most of their news through influencers or partisan social media, and people who barely think about news at all will create a fundamental schism in how Americans see the world.”<sup>7</sup> Jill Lepore’s recent piece in The New Yorker poses the question of whether it is “too late to turn back” now as American civic life has become increasingly shaped by algorithms.<sup>8</sup><br><br>In this new era of communicative abundance, Marshall McLuhan’s famous formula—the “medium is the message”<sup>9</sup> distributed in a “global village”<sup>10</sup> without restraint—has reached a new level of boundlessness. The message, based on a deliverer’s whim, becomes the medium. Governments, regulators, and other branches of the state are not prepared for the threats tied to generative AI<sup>11</sup> now widely being used to spread misinformation. (Amongst other things, they now also have groups of non-human actors to consider). Publicly, lawmakers, tech executives, and outside groups monitoring worldwide elections have urged caution when dealing with technology developing faster than it can be controlled.<sup>12</sup> In particular, generative AI and synthetic media posed significant risks of abuse in the 2024 U.S. election cycle.<br><br>The risks of AI-fueled disinformation and algorithmic distortion of our civic debates are everywhere, but they are likely to be even more pronounced in non-Western regions of the world where social media corporations are known to under-invest in safeguards (i.e. Trust and Safety boards largely only exist in the Global North). In authoritarian, rogue, or unstable regimes, bad actors are able to exploit the chaos of the Infocalypse with greater impunity (although no political system or country is immune). Mis and disinformation have been causing chaos and even inciting genocidal violence in places like the Philippines, Myanmar, and India (Indian political parties are estimated to spend over $50 million on AI-generated election campaign material this year<sup>13</sup>)—before the West woke up to the problem with the Russian-led U.S. election interference of 2016.<br><br>Western democracies still have defenses in the rule of law, the free press, and democratic institutions, all of which are established (even as they become increasingly vulnerable). In countries where there are no institutional safeguards, however, the consequences of the corroding information ecosystem could be even more devastating. Our shared reality is at stake when the Infocalypse is broadly being used to threaten and intimidate domestic opposition, drown out dissenting opinions, incite violence (ethnic and/or gender), and suppress fundamental human rights.<h3>Where We’re Headed</h3>Much of the technical expertise required to make changes to the algorithms to “win” the current information war resides deep within Big Tech companies. Platform growth is prioritized over values, as companies like Meta reside at the intersection of media and capitalism. Polarization, for them, is merely a negative externality of their business model for maximizing profit.<br><br>Legislative efforts, including the European Union’s recently-passed Artificial Intelligence Act, are, at best, works in progress (although firm wide AI literacy, mandated by the EU AI Act, is a start). The near total lack of oversight of how social media platforms’ AI-powered algorithms<sup>14</sup> operate makes it impossible to rely on anyone other than tech giants themselves to police how these systems determine what people see online.<br><br>Where I believe we’re heading, though, is a “post-post-truth” era, where people will think everything is made up, especially online. Think “fake news,” but to the utmost extent where not even the most seemingly authentic content on the BBC can be presumed to be 100 percent true. With the hysteria around AI often outpacing what the technology can currently do — despite daily advances — there’s now a widespread willingness to believe all content can be created via AI, even when it can’t. In such a world, it’s rational to not have faith in anything.<br><br>Speaking from experience, the Russian “firehose of falsehood” propaganda model of drenching and confusing people with information to force them to give up caring works. The majority of Russian people claim that the Kremlin is the innocent party in its brutal invasion of Ukraine<sup>15</sup>. When Ukrainians call their relatives in Russia to tell them about the atrocities, all too often they hear their own kin parrot the Kremlin’s propaganda lines.<sup>16</sup><br><br>As a Gen-Z-er, watching my own generation’s relationship to politics degrade into a mistrust of legacy media has made me realize that the survival of liberal democracy will depend upon the integrity of each new generation’s media environment. Across the world, there has been a growth of propaganda that promotes an alternative reality where truth is cast away in favor of a sense of superiority and paranoia.<br><br>In 2016, Oxford Dictionary’s word of the word was “post-truth”<sup>17</sup>. This year, it is “polarization”. We have come a long way since 2016 in our understanding of “fake news” and disinformation research, but are no closer to finding a solution to the problem’s root. In the face of a populist, power-based order, truth is no longer factual but what others can be persuaded to believe. Combined with “brain rot”<sup>18</sup> and “brat”<sup>19</sup>, the 2024 words of the year point to the power, perils and ephemeral nature of digital life.",
              "works-cited": [
                "Furman, A. ““Polarization” Is Merriam-Webster’s 2024 Word of the Year.” AP News, 9 Dec. 2024, apnews.com/article/word-year-merriam-webster-2024-df39b7a3651f041ac6812155f1f67f45",
                "Bremmer, Ian [@ianbremmer.com]. “should be word of the decade honestly” BlueSky, 9 December 2024, https://bsky.app/profile/ianbremmer.com/post/3lcvhq54fes2q",
                "Machiavelli, Niccolò. The Prince. 1532. New York, Ams Press, 1967.",
                "NVIDIA. “What Is a Recommendation System?” NVIDIA Data Science Glossary, 2024, www.nvidia.com/en-us/glossary/recommendation-system/",
                " Killian L. McLoughlin et al. Misinformation exploits outrage to spread online. Science 386,991-996(2024).DOI:10.1126/science.adl2829",
                "Malone, C. (2024, February 10). Is the Media Prepared for an Extinction-Level Event? The New Yorker. https://www.newyorker.com/news/the-weekend-essay/is-the-media-prepared-for-an-extinction-level-event",
                "Marwick, A. (2024). The mainstream media will lose its last grip on relevancy. Nieman Lab. https://www.niemanlab.org/2024/12/the-mainstream-media-will-lose-its-last-grip-on-relevancy/",
                "Lepore, J. (2024, November 4). The Artificial State. The New Yorker. https://www.newyorker.com/magazine/2024/11/11/the-artificial-state",
                "Mcluhan, M. (1964). Understanding Media: The Extensions of Man (pp. 3–18). Gingko Press.",
                "Ibid.",
                "Scott, M. (2024, April 16). Deepfakes, distrust and disinformation: Welcome to the AI election. POLITICO;  POLITICO. https://www.politico.eu/article/deepfakes-distrust-disinformation-welcome-ai-election-2024/",
                "Scott, M., Volpicelli, G., Chatterjee, M., Manancourt, V., Clothilde Goujard, & Bordelon, B. (2024, March 26). Inside the shadowy global battle to tame the world’s most dangerous technology. POLITICO. https://www.politico.eu/article/ai-control-kamala-harris-nick-clegg-meta-big-tech-social-media/",
                " Shah, F. (2024, April 30). AI companies are making millions producing election content in India. Rest of World. https://restofworld.org/2024/india-elections-ai-content/",
                "Scott, Mark, et al. “Anatomy of a Scroll: Inside TikTok’s AI-Powered Algorithms.” POLITICO, 7 May 2024, www.politico.eu/article/anatomy-scroll-inside-tiktok-ai-powered-algorithm-israel-palestine-war/",
                "Goryanov, A. (2023, February 22). Ukraine war: Why so many Russians turn a blind eye to the conflict. BBC News. https://www.bbc.com/news/world-europe-64703768",
                "Lucas, R. (2022, March 7). Ukrainian-Russian families are being torn apart by Russia’s invasion. NPR.org. https://www.npr.org/2022/03/06/1084800742/relationships-across-the-ukraine-russia-border-feel-the-strain-of-war",
                "Oxford Languages. (2016). Oxford Word of the Year 2016. Oup.com. https://languages.oup.com/word-of-the-year/2016/",
                "Heaton, B. (2024, December 2). “Brain rot” named Oxford Word of the Year 2024 - Oxford University Press. Oxford University Press. https://corp.oup.com/news/brain-rot-named-oxford-word-of-the-year-2024/",
                "Rahimi, R. (2024, November). Collins Dictionary’s word of the year is a confident, messy way of life. CNN. https://www.cnn.com/2024/11/01/style/brat-word-of-the-year-collins-dictionary-intl-scli/index.html"
              ],
              "images": [
                {
                  "url": "/images/KATYA_FINAL.png",
                  "caption": "An illustrative image",
                  "alt_text": "Image showing zine artwork"
                }
              ]
            }
          },
          {
            "id": "anon-title-tba",
            "category": "Hidden Narratives",
            "title": "MY INTRODUCTION TO THE MINECRAFT TO CYBERCRIME PIPELINE",
            "author": {
              "name": "ANONYMOUS",
              "email": "anon@newschool.edu",
              "bio": ""
            },
            "content": {
              "body": "At 11 years old, I first discovered online games, like Minecraft, which became my escape from the small, insular world of Chatham, Massachusetts. Growing up in a town where I’d known the same eighty kids since kindergarten, I longed to escape . Minecraft became my gateway—a place where I could slip into the persona of \"User,\" the fearless leader of my faction. The friends I made online felt as real as any in person, opening my eyes to perspectives I’d never encountered in my everyday life.<br><br>This was the story I shared in my college application  essay, one that helped me gain acceptance to colleges with less than 9% acceptance rates. In that essay, I described how my time online taught me empathy, curiosity, and design, bringing me closer to the person I wanted to become.<br><br>But there was more to that story—parts I left out, not because I was ashamed, but because they felt too raw for a college application. Over the years, I spent roughly 15,000 hours in my room, my family assuming I was just playing Minecraft. In reality, I was interacting with hundreds of people online, some with nefarious intentions like pedophiles and criminals.  These interactions would shape how I saw the world, particularly how power works in a connected, digital society. I was DDosed (Distributed Denial of Service), threatened, and even doxxed, but that wasn't a unique experience for someone playing hardcore factions(HCF) from 2012 to 2018. For all its chaos, this experience became an unconventional education. Despite everything, I am deeply grateful for what I learned.<br><br>This article will both touch on my personal experiences with the Minecraft to cybercrime pipeline and  explore the broader culture of Minecraft’s online world—a world that shaped not only me but also countless others, rippling outward to influence the larger cyber landscape. From DDoS attacks to account hijacking, the knowledge shared among  this community—whether used positively or not—has had lasting effects.<br><br>Doxxing, for example,the practice of exposing someone’s personal information online, seemed like an abstract danger until I became  its target. One day, someone identified my school’s name in a game chat. I couldn’t unsee the message. Someone, somewhere, knew exactly where I was. \"User\" was supposed to be my persona, my shield. But suddenly,  I wasn’t protected—a stranger  not only knew where I attended school but also knew my home address, my parents’ names, everything. Each day, I walked into school with completely chewed through fingernails and anticipated the possibility of hearing my name over the loudspeaker or seeing the police waiting at my school. To my relief, nothing ever came of this, but I remained uneasy for many years.<br><br>I still keep in touch with friends I made online when I was just 11, many of whom, like me, are now on paths to achieving great things in life. While none of us ever crossed any major lines, it’s striking how often I hear about someone we knew—either closely or loosely—being arrested for cybercrimes, with some facing over 25 years in federal prison. Even those cases barely scratch the surface of the cybercriminals who emerged from the HCF community.<h3>Paras Jha - Cybercriminal</h3>Minecraft’s open-ended gameplay and competitive server culture have long-served as fertile ground for experimentation and innovation. For Paras Jha, a Rutgers University computer science major and Minecraft enthusiast, it was more than just a game—it was the starting point for one of the most consequential cyberattacks of the decade.<br><br>Jha’s story is a cautionary tale of how curiosity and technical skill can spiral into something far more disruptive. His early involvement in Minecraft server wars introduced him to DDoS attacks, a tactic often used to overwhelm a rival server with traffic until it crashes. In the high-stakes world of Minecraft servers, where hosting a popular server could mean earning tens of thousands of dollars per month, DDoS attacks became a common tool of sabotage. Jha’s technical expertise led him to create and sell DDoS protection services to server owners—essentially running what prosecutors later described as a high-tech protection racket.<br><br>But Jha’s ambitions didn’t stop at Minecraft. Along with two collaborators, Josiah White and Dalton Norman, he developed the Mirai botnet, a powerful piece of malware that hijacked Internet of Things (IoT) devices—smart cameras, routers, and other internet-connected gadgets—to create a network of hundreds of thousands of compromised devices. With this botnet, the trio launched DDoS attacks on a scale never seen before. One of the most infamous incidents occurred in October 2016, when Mirai was used to attack Dyn, a major DNS provider, disrupting internet access across the United States and taking down websites like Twitter, Netflix, and PayPal for hours.<br><br>The irony of Mirai’s origins isn’t lost on those familiar with Jha’s background. What began as tactics to dominate Minecraft servers—crippling competitors and securing a larger player base—evolved into attacks targeting critical internet infrastructure. Mirai’s ability to exploit IoT devices exposed a glaring vulnerability in modern technology: the lack of basic security measures in the rapidly growing ecosystem of connected devices.<br><br>Even before Mirai, Jha made headlines for his attacks on Rutgers University’s computer network, where he was a student. Using the alias “exfocus,” he launched a series of DDoS attacks during exam periods, causing widespread disruption to internet access and online resources for students and faculty. The attacks, which forced Rutgers to spend millions on cybersecurity upgrades, were as much a statement of defiance as they were a demonstration of Jha’s technical prowess.<br><br>Mirai’s release as open-source code in September 2016 marked a turning point. By publishing the malware online, Jha and his collaborators sought to obscure their involvement and create plausible deniability. Instead, they unleashed a tool that hackers worldwide quickly adapted for their own purposes. Within weeks, new variants of Mirai were used to launch attacks against organizations, governments, and even entire countries. The widespread availability of Mirai democratized the ability to conduct large-scale DDoS attacks, amplifying the chaos it could cause.<br><br>Brian Krebs, the cybersecurity journalist whose site was knocked offline by Mirai, described Jha as emblematic of a generation raised on games like Minecraft, where building, breaking, and experimenting were second nature. “The game is brilliant in a lot of ways,” Krebs noted, “but it also teaches you how to think about systems in ways that aren’t always positive.” Jha’s path—from Minecraft devotee to architect of one of the largest botnets in history—demonstrates both the power and the danger of technical expertise developed in an unregulated environment.<br><br>Ultimately, Jha’s actions caught up with him. After an extensive investigation, he and his collaborators pleaded guilty to charges of conspiracy to violate the Computer Fraud and Abuse Act. While Jha avoided prison time in exchange for cooperating with federal authorities, the damage caused by Mirai and its variants continues to ripple across the internet.<br><br>Jha’s story highlights a fundamental truth about the digital world: the same skills that empower creativity and innovation can also enable exploitation and destruction. What began as a way to dominate a Minecraft server grew into a global lesson about the consequences of unchecked ambition in an interconnected world.<h3>Graham Clark - Social Engineer</h3>While Paras Jha weaponized his coding expertise to create one of the most devastating botnets in history, Graham Ivan Clark—known in gaming and hacking circles as “Open” or “OpenHCF”—epitomizes the archetype of the manipulative social engineer. Unlike Jha’s technical precision, Clark’s rise in the digital underworld was fueled by his charisma, psychological acumen, and an unrelenting pursuit of wealth. His journey from scamming Minecraft players to orchestrating one of the most infamous Twitter hacks of all time is both a cautionary tale and a disturbing reminder of the power dynamics that shape online communities.<br><br>Clark’s story begins in the chaotic world of Minecraft Hardcore Factions (HCF), a highly competitive game mode notorious for fostering toxic behavior. By the age of 10, Clark had already built a reputation as a cunning player, manipulating others to gain resources and power. He would promise to sell in-game items like rare capes or coveted OG usernames, only to vanish after receiving payment. As his reputation grew, so did his audacity. Former peers recount how Clark’s charm masked a ruthless streak: he could convince others to help him build his scams, only to leave them burned and humiliated. One of his accomplices described Clark’s attitude as a combination of greed and detachment—he was unbothered by the fallout of his actions.<br><br>This toxic environment wasn’t just a backdrop; it was a training ground. HCF players engaged in activities like doxxing, DDoS attacks, and swatting, which blurred the lines between online mischief and criminal behavior. For Clark, this world was a gateway to broader schemes. By 2016, his exploits extended to OGUsers, a forum where stolen social media accounts and rare usernames were bought and sold. The username “Open,” which he used in Minecraft and hacking communities, likely originated from these markets, where he refined his skills in social engineering. Unlike hacking tools, which require technical expertise, social engineering is a psychological game. Clark excelled at this, manipulating people into giving up credentials or access under false pretenses.<br><br>At just 15, Clark transitioned from Minecraft scams to SIM-swapping, a more lucrative and dangerous form of cybercrime. By exploiting weaknesses in phone carrier systems, Clark and his accomplices could hijack victims’ phone numbers, reset passwords, and drain cryptocurrency wallets. In 2019, he executed a SIM-swap attack that netted him $856,000 worth of Bitcoin from a Seattle tech investor. While authorities eventually linked him to the crime, Clark avoided formal charges by returning part of the stolen funds. This brush with law enforcement seemed to embolden him rather than deter him.<br><br>Clark’s most infamous exploit came in July 2020, when he orchestrated the Twitter hack that compromised accounts of high-profile figures, including Barack Obama, Elon Musk, and Bill Gates. Posing as an IT employee, Clark accessed Twitter’s internal systems via a phishing scheme targeting employees working remotely during the COVID-19 pandemic. Once inside, he hijacked celebrity accounts to post a Bitcoin-doubling scam, earning $117,000 in cryptocurrency. This figure paled in comparison to his previous exploits, but the hack’s audacity made it the biggest security breach in Twitter’s history. At the time of his arrest, authorities discovered Clark had an additional $3 million in Bitcoin, likely accumulated through years of fraud.<br><br>Clark’s ability to navigate online spaces with ease was a testament to his adaptability and cunning. He wasn’t just a scammer; he was a product of the digital culture that shaped him. The HCF community had normalized behaviors like account theft and harassment, framing them as clever tactics rather than moral failures. By the time Clark moved on to more sophisticated crimes, he had already built a network of accomplices and a reputation as a skilled manipulator.<br><br>Yet, his story is also a tale of hubris. Clark’s boldness, flaunted wealth, and disregard for consequences made him a target. After the Twitter hack, his co-conspirators—many of whom were recruited from OGUsers—quickly turned on him, accusing him of greed and withholding stolen funds. The FBI arrested him just weeks after the hack, charging him with 30 felonies, including wire fraud and identity theft. Due to his juvenile status, Clark struck a plea deal, serving only six years under Florida’s youthful offender law.<br><br>The rise and fall of Graham Ivan Clark illuminate the dark underbelly of online gaming and hacking cultures. From Minecraft scams to multi-million-dollar cryptocurrency thefts, Clark’s journey reveals how toxic environments can incubate criminal talent and how digital anonymity can foster a detachment from ethical considerations. His story serves as a stark reminder of the societal risks posed by these insular, exploitative communities—and the need to address the conditions that allow them to thrive.<h3>Aspartame - Hacker</h3>Aspartame's name became synonymous with terror in the Minecraft HCF (Hardcore Factions) community, a realm already infamous for its cutthroat culture and toxic dynamics. What began as in-game trolling and petty scams quickly evolved into a pattern of harassment and abuse so extreme that it left a trail of fear far beyond the confines of the virtual world.<br><br>At first, Aspartame was a nuisance—one of countless players who blurred the line between competition and cruelty. His early antics, which included hacking accounts and leaking personal information, were a common feature of the HCF landscape. But Aspartame's appetite for power and control soon outgrew the game itself. He began compiling databases of personal information, leveraging doxxing bots to pull private details about anyone who crossed his path. For him, it wasn’t just about winning; it was about destruction.<br><br>His favorite weapon of choice was swatting. With a single call, he could turn someone’s home into a scene of chaos, sending armed police to respond to fabricated emergencies. One victim recalled watching from a window as their house was surrounded by SWAT officers, guns drawn, after a false report claimed there had been a murder inside. Another family endured hours of interrogation because Aspartame had hacked their Ring doorbell, taunting them with threats while they listened in terror. Over the course of one week, he orchestrated swatting attacks across twelve states, terrorizing families who had no connection to his online world.<br><br>These weren’t isolated incidents; they were a pattern. In one particularly harrowing case, a school received a bomb threat that prompted a full evacuation. The call wasn’t random—it was part of Aspartame's systematic campaign to destroy the lives of those who had the misfortune of crossing him. He didn’t just want to scare his victims; he wanted them to feel utterly powerless. For Aspartame, this was a sport.<br><br>But his cruelty didn’t stop with swatting. Perhaps the most disturbing aspect of Aspartame's behavior was his exploitation of young girls. Using the personal information he had collected, he extorted them into sending degrading photos of themselves—known as “fan signs”—to prove their submission. For many victims, this wasn’t just an invasion of privacy; it was a deeply traumatic experience that drove them offline or left them isolated and afraid.<br><br>Aspartame bragged openly about these extortions, inviting others to join his twisted games. In one group chat, he coerced a 13-year-old boy into writing his name on his face, threatening to call in a bomb threat to the boy’s school if he refused. He leveraged his power in Discord servers, creating bots capable of pulling detailed personal information on players with a single command. The fear he inspired was so pervasive that even seasoned hackers hesitated to challenge him.<br><br>The culture of the HCF community, with its unchecked toxicity and emphasis on power, provided fertile ground for Aspartame's rise. Server administrators, well aware of his reputation, often turned a blind eye or even collaborated with him. On one server, he paid for administrative privileges, which he used to manipulate and harass players. On another, he blackmailed staff into lifting bans against Eventually, Aspartame's actions drew the attention of law enforcement. A series of bomb threats and swatting incidents triggered an FBI investigation, culminating in his arrest in 2022. Despite wiping his computer before authorities arrived, his trail of crimes was too extensive to conceal. He ultimately pleaded guilty to multiple charges, including identity theft and conspiracy, and was sentenced to seven years in prison.<br><br>Even now, the fear he sowed lingers. His victims—some as young as 13—continue to grapple with the trauma he inflicted. Families upended by swatting incidents recall the nights they spent in terror, wondering if they would survive. And yet, Aspartame's story is more than just a cautionary tale about one individual’s descent into cruelty. It’s a reflection of a digital culture that too often rewards the worst behaviors, a warning about what can happen when communities prioritize power over accountability.<h3>Conclusion:</h3>Through these stories, I hoped to offer a clearer understanding of the Hardcore Factions (HCF) community and its peculiar evolution into a breeding ground for cybercrime and illicit activity. While no singular explanation can account for why this gamemode attracted so many individuals who turned to criminality, my own experience suggests that it fostered a \"frat-like\" brotherhood. This bond could be both empowering and destructive, creating a sense of shared identity that often blurred the lines between camaraderie and complicity.<br><br>Looking at this through the framework of this class, I seek to  illustrate how unregulated digital spaces and communities can evolve into powerful, yet often destructive, ecosystems. HCF and similar subcultures thrive on the misuse of data, anonymity, and exploitation of trust, creating environments where digital tools can be weaponized in ways their creators never intended. These spaces are microcosms of larger discussions about the ethical dimensions of data and technology, emphasizing how the lack of oversight and accountability can lead to unforeseen consequences.<br><br>The relevance of examining these stories lies in its ability to highlight the unintended intersections of technology, behavior, and community dynamics. These stories force us to grapple with the dual-edged nature of digital innovation: the same tools that empower can also be used to exploit. Understanding how these ecosystems operate is essential for addressing the broader societal implications of data and technology in our lives. Ultimately, the story of HCF is a cautionary tale—a reminder of the potential for technology to shape our futures in unexpected ways, for better or worse.<br><br>",
              "images": [
                {
                  "url": "/images/ANON_FINAL.png",
                  "caption": "An illustrative image",
                  "alt_text": "Image showing zine artwork"
                }
              ]
            }
          },
          {
            "id": "di-murray-title-tba",
            "category": "Hidden Narratives",
            "title": "THE PHILIPPINES ON THE NEW FRONTLINES OF THE COLD WAR",
            "author": {
              "name": "DI MURRAY",
              "email": "murrd426@newschool.edu",
              "bio": ""
            },
            "content": {
              "body": "It seems impossible in today’s 24-hour news cycle to go even a moment without hearing about another escalation between the United States and China. Social media, in particular, has become a petri dish for viral stories to spread, from alleged spy balloon sightings to protested presidential visitations, and a battleground for this developing cold war in the information age. But what does this war actually look like? As global superpowers fight to gain ground in this new digital frontier, how can individual actors better understand the changing nature of this conflict and perhaps even the future of warfare as a whole?<br><br>On June 14th 2024, investigative journalists for Reuters, Chris Bing, and Joel Schectman broke a damning story about how a digital warzone was manifesting in the Philippines during the height of the pandemic. After going unreported for nearly three years, Reuters exposed a psychological operation coming out of the Pentagon involving the deployment of hundreds of botted accounts across X and Facebook, all designed to push a mass disinformation campaign and promote distrust in Chinese-made PPE, test kits, and the Sinovac COVID-19 vaccination<sup>1</sup>. Beginning in 2020, using #ChinaAngVirus or #ChinaIsTheVirus hashtags, the accounts posed as dissatisfied Filipino citizens and shared messages and memes insinuating that the vaccine contained anything from pork fat to rat poison<sup>2</sup>. In reality, the accounts were being run out of MacDrill Air Force Base in Tampa, Florida, managed and maintained by a defense contractor called General Dynamics. For the next year and a half, the program would flood Filipino social media with anti-Chinese propaganda, eventually expanding into similar disincentivization psyops in Central Asia and the Middle East targeting Muslim communities<sup>3</sup>.<br><br>While the operation transitioned over from the Trump administration to the Biden administration during the 2020 election, there was internal hesitancy over the continuation of the program. Normally, in peacetime, the Pentagon needed approval of embassy officials before conducting psyops; but, in 2019, then-Secretary of Defense Mark Esper signed a secret order that would lay the groundwork for what was to come. The order elevated the Pentagon’s competition with China and Russia to the priority of active combat<sup>4</sup>, enabling commanders to sidestep the State Department when conducting psyops against those adversaries. Several officials from the Department of Defense saw it as the “crossing of a line” during a public health crisis. However, the operation survived well into Biden’s first months in the White House; a senior officer who had been involved with the program noted that “We weren’t looking at this from a public health perspective. We were looking at how we could drag China through the mud<sup>5</sup>.”<br><br>While it's impossible to truly know how many people were specifically targeted by the Pentagon’s campaign in the Philippines, it cannot be underscored how devastating the impacts of a psyop like this are. At the time of the operation in 2021, the Philippines had one of the lowest inoculation rates in Southeast Asia, at less than 4% of the total population, while maintaining a staggering rate of infection<sup>6</sup>. Additionally, Al Jazeera reported that, in 2021, two-thirds of Filipinos were unwilling to receive a vaccine while a 2022 study conducted by PLOS Global Public Health listed online misinformation as a key factor in “vaccine hesitancy<sup>7</sup>.” One patient from the study even remarked that their least preferred vaccine brand is Sinovac because of its country of origin. I do not believe in China.” This illustrates the kind of damage that a mass disinformation campaign like the Pentagon’s leaves in its wake. To rebuild trust in vaccination and public health services takes years, if not decades, all while people continue to suffer from preventable illnesses. In the Philippines today, four years out from the beginning of the military’s operation, over 66,000 people have died from COVID-19<sup>8</sup>. One has to imagine that number could have been reduced had people not been told that their vaccinations were filled with poison.<br><br>This was not the first time the US military has carried out a psyop in the region. In the early 1950’s, CIA operatives targeted the Hukbalahap, a guerilla front formed to fight off Japanese occupation, as a communist threat to post-war order<sup>9</sup>. The CIA abducted, tortured, and mutilated members of the group, puncturing holes in their necks and draining their bodies of blood before laying out the corpses across the countryside so that local communities would associate the guerillas with the aswang monsters of Philippine folklore. This brutality lays the context for the Pentagon’s psychological operations in the country today. Going back to 1902 and the end of the Philippine American War, the Philippines was a prized colony for the United States due to its wealth of natural resources and advantageous position as a gateway to the rest of Asia. The motivations underlying the United States’ vested interest in keeping the Philippines out of China’s sphere of influence remain largely unchanged from its original colonial goals.<br><br>So how does this covert disinformation campaign in the Philippines help reshape our understanding of the brewing cold war between the US and China? Well, for one thing, it shows that the war has already begun. As demonstrated by Secretary of Defense Esper’s 2019 order, we are in a time of active combat, where the rules of war can be cast aside in favor of winning and where someone is better off dead than influenced by the other side. Additionally, it helps us understand where this war is being fought: Where the media chooses to center the conflict around disputed territory like Taiwan or the South China Sea, the Pentagon’s targets for their psychological operations help shift focus and think wider. The war is being fought in dark server rooms in Tampa where the internet makes battlefields out of flooded graveyards in the slums of Manila. While the technology of warfare may have changed, ultimately, the imperial mechanism stays the same. And so this time, in this war, the first casualties may not result from bullets, but instead from  tweets.",
              "works-cited": [
                "Schectman, Joel, and Chris Bing. “Pentagon Ran Secret Anti-Vax Campaign to Undermine China during Pandemic.” Reuters, 14 June 2024, www.reuters.com/investigates/special-report/usa-covid-propaganda/.",
                "ibid",
                "Skopic, Alex. “Prosecute the U.S. Officials Who Spread Lies about China’s Vaccine.” Current Affairs, Current Affairs, 19 June 2024, www.currentaffairs.org/news/prosecute-the-u.s.-officials-who-spread-lies-about-chinas-vaccine.",
                "ibid",
                "ibid",
                "Amit, Arianna Maever L et al. “COVID-19 vaccine brand hesitancy and other challenges to vaccination in the Philippines.” PLOS global public health vol. 2,1 e0000165. 13 Jan. 2022, doi:10.1371/journal.pgph.0000165",
                "Gotinga, JC. “Win a Cow, Avoid Covid: Philippines Tempts Vaccine Hesitant.” Al Jazeera, Al Jazeera, 14 June 2021, www.aljazeera.com/news/2021/6/14/win-a-cow-avoid-covid-philippines-tempts-vaccine-hesitant",
                "Amit, Arianna Maever L et al. “COVID-19 vaccine brand hesitancy and other challenges to vaccination in the Philippines.” PLOS global public health vol. 2,1 e0000165. 13 Jan. 2022, doi:10.1371/journal.pgph.0000165",
                "Severino, Allen, and Anri Ichimura. “How the CIA Used the Aswang to Win a War in the Philippines.” Esquiremag.Ph, Esquire Philippines, 4 Nov. 2019, www.esquiremag.ph/long-reads/features/cia-aswang-war-a00304-a2416-20191019-lfrm?s=tgavgcrihbuiorsvj9fj3l1nm"
              ],
              "images": [
                {
                  "url": "/images/DI_FINAL.png",
                  "caption": "An illustrative image",
                  "alt_text": "Image showing zine artwork"
                }
              ]
            }
          }
        ]
      }
    }
  }
}
