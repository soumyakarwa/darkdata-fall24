{
  "zine": {
    "name": "Dark Data",
    "issue": "Fall 2024",
    "publication_date": "2024-12-07",
    "categories": {
      "digital-misogyny": {
        "id": "digital-misogyny",
        "section-title": "Digital Misogyny",
        "articles": [
          {
            "id": "neven-armanios-rodriguez-title-tbd",
            "title": "THE PROBLEM WITH INCOMPLETE DATA",
            "subtitle": "The Data that Misinforms and only Scratches the Surface",
            "author": {
              "name": "NEVEN ARMANIOS",
              "email": "ashrf576@newschool.edu",
              "bio": ""
            },
            "content": {
              "body": "With every New Year approaching, I prepare to make new year’s resolutions, and there is always one resolution that I strive to fulfill — losing weight. This year, as we reach the end of 2024, I will probably make the same resolution. But, in 2025, this resolution will not involve intermittent fasting. I tried that already. It did not work. In the past, whenever I repeatedly tried not eating for a good part of the morning and early afternoon, my efforts to lose weight came up short. Why? I discovered that women do not benefit from intermittent fasting in the same way that men do. Turns out that the data historically praising the results of intermittent fasting relied on aggregated data - data where the majority if not all of the subjects were male. One of the first clinical studies to investigate intermittent fasting was done on men, published in the Journal of Nutrition, Health, and Aging, in 2013 (Hussin et al). The study had a total of 32 healthy males aged around 59.7±6.3 years. No women were included in this preliminary study.<br><br>It was actually my female general practitioner who pointed out that my efforts with intermittent fasting might be futile. I learned from her that the data that was available to me during my attempts to fast intermittently was likely lacking and misleading. From what I read online, I assumed that the benefits of fasting would be experienced by most if not all who changed their dietary consumption timeframe. A study by Alum at al found that “Intermittent fasting is a beneficial concept for increasing the quality of life, for weight loss, for metabolism, and even for increasing the lifespan. However, the impact is considered to be different in men and women, for example, in hormonal shifts, alterations in body composition, energy levels, and the reproductive system” (Alum et al). When women are much more vulnerable to hormonal imbalance than men, they often don't see the same results as men with intermittent fasting. Studies examining intermittent fasting effects on women are limited and additional studies are required to gain knowledge that highlights the distinctions between the sexes.<br><br>In fact, I have noticed that on many issues, the data on women is either missing or incomplete. Therefore, I am sharing instances where I, as a woman, was affected by the shortage of information, and that’s how I noticed this shortage of female-centric data. If we look at issues that are less personal to me and more global, such as climate change, again we observe that the data collected on women falls short.<br><br>The state of the planet was different in the 2000s, or at least not as seriously in peril as it is today. However, if in 2008, when I was pregnant with my son, if the climate was anything like what we are dealing with in 2024, I may have faced serious vulnerabilities as a pregnant woman. Interested in the impacts of climate change on  women specifically, I searched for data. I learned that climate change poses risks to pregnant women in particular. Not only does global warming affect women differently than it affects men, it affects pregnant women, and their unborn babies, differently than non-pregnant women. For instance, according to the United States Environmental Protection Agency, 1 out of 10 infants born in 2019 in the United States were born preterm (before 37 weeks of pregnancy completed) due to a mother's exposure to extreme heat (EPA). And studies suggest climate change affects women both in wealthier nations and in poorer countries.<br><br>In less developed countries, climate-related destructive patterns, including extreme heat, flooding, and wildfires, have been linked to pregnancy-related health problems such as low birth weight, preterm birth, and even miscarriage. This data is not widely accessible and, sadly, not enough research has been done on this topic.<br><br>Women also face another issue in many countries where water is scarce. With 1.8 billion people living in households without water supplies on the premises, women and girls aged 15 and older are primarily responsible for water collection in 7 out of 10 such households (UNICEF).  After a drought or natural disaster due to climate change, these same women and girls must travel longer and further to find water, at times placing themselves in danger. Yet, studies conducted on the impacts of climate change do not deaggregate the data to provide insights needed to see how one gender is exponentially affected more so than another gender. Nor are there enough efforts made to collect data about women affected by global warming. This lack of data can create doubts about whether women are truly affected differently, in this case, by climate change.<br><br>You may be questioning this hypothesis yourself. It was definitely controversial amongst my friends and at my university when I started to discuss it. Some people were surprised and questioned this hypothesis. Why? — because there has not been enough of a focus by practitioners in the field of global warming to collect more specific data. Whether one agrees that women face different risks because of climate change than men is not the issue. The issue is that the data we do have scratches the surface. The challenge to collect gender-specific data is ubiquitous due to cultural norms and privacy issues. However, protecting an individual's privacy while gaining data necessary for accurate insight is possible. Rather than ignoring a particular demographic completely by aggregating the data, disaggregating the data is needed. Research topics, where consequential data collection is necessary, requires inclusivity and the active account of different populations. In the example of climate change and women, we do not have enough data to understand thoroughly what women and girls have to contend with, and this is a problem.<br><br>Data can also be unreliable for a number of reasons, even when it is technically accurate. This was the case with intermittent fasting for me. The same can be seen with research conducted on artificial sweeteners that often fail to account for critical factors that could clarify the true health impacts. People typically turn to nonsugar sweeteners after developing health issues like diabetes or weight gain, leading to a misconception that these sweeteners do not worsen the very problems they were intended to help manage. Many studies rely on self-reported consumption data, which is unreliable, because sweeteners are often hidden in ingredient lists. This is just one other found example that has been recorded. Many examples are non-existent because researchers have not focused enough on collecting targeted, comparative data. It’s simply missing.<br><br>Efforts are being made to raise awareness around gaps in data collection. For instance, Mimi Onuoha, a Nigerian-American artist, shows the contradictions between the advancement of technology and the obscurity of accurate data. Through her installations, she draws attention to missing data: information that is absent. In her project titled “The Library of Missing Datasets” (Figure 1-2), we observe file cabinets with labeled folders, which are empty. For instance, the folder labeled “Number of Americans without bank accounts in 2008,” is empty. What does that suggest? It suggests that even though this is an existing issue, since there is no data collected on it, it is easy to overlook and to consider it non-existent and not important (Onuoha).<br><br><div class=image-container><img src=\"/images/NEVEN_IMAGE1.jpg\"><p class=caption>Fig. 1. Mimi Onuoha. “The Library of Missing Datasets.” 2018.</p><img src=\"/images/NEVEN_IMAGE2.jpg\"><p class=caption>Fig. 2. Mimi Onuoha. “The Library of Missing Datasets.” 2018.</p></div><br><br>Onuoha also explicitly states that Black people are both “over-collected” and “under-represented” with data. What she means by that is that the lack of data about Black populations is a significant issue; comprehensive and detailed data regarding demographics, health issues, socioeconomic status, and other key aspects of life are often missing or insufficient. This absence of data makes it difficult to accurately understand and address disparities faced. Factors such as historical underrepresentation in research studies, data collection limitations, and mistrust within the community towards research initiatives are to blame.<br><br>Due to systemic racism, the exclusion of Black people from research studies limits the data available on health and social experiences. The data, at times, is aggregated, masking important variables, and in turn, makes it difficult to identify specific needs. For instance, studies like the Tuskegee Syphilis Study (CDC) have created a deep distrust among African Americans towards medical research, leading to lower participation rates in studies.<br><br>Without accurate data, policymakers will struggle to design effective programs that address the specific needs of African Americans while researchers and physicians will not be able to effectively treat their health. For example, when it comes to cancer research, African Americans “make up about 14% of the U.S. population but only 5% to 7% of clinical trial participants. Clinical trial participation is important because it provides people with the opportunity to access new cancer treatments, tests, and approaches to improving cancer care” (Jaber). All too often, African Americans are not adequately represented in research studies because their data was never collected and analyzed.<br><br>As both my personal experiences and these studies highlight, data collection can go wrong due to a lack of data, misleading data, or inaccurate data. Disaggregated data is often not available because it doesn’t get collected. Sadly, as we’ve seen, datasets often only scratch the surface of an issue and could be described as incomplete, misleading or inaccurate.<br><br>",
              "works-cited": [
                "Alum, Esther Ugo, Emmanuel Ifeanyi Obeagu, Okechukwu Paul-Chima Ugwu, Benedict Nnachi Alum, Echegu Darlington Arinze1, Chris U. A. Ukaidi. “Exploring the Differential Impacts of Intermittent Fasting on Men and Women.” Elite Journal of Health",
                "Sciences. Volume 2, Issue 5, 2024, pp.  37-44. https://www.researchgate.net/publication/381740409_Differential_Impacts_of_Intermittent_Fasting_on_Men_and_Women",
                "CDC. “About The Untreated Syphilis Study at Tuskegee.” https://www.cdc.gov/tuskegee/about/index.html ",
                "EPA. “Climate Change and the Health of Pregnant, Breastfeeding, and Postpartum Women.” United States Environmental Protection Agency website. https://www.epa.gov/climateimpacts/climate-change-and-health-pregnant-breastfeeding-and-postpartum-women.",
                "Jaber, Nadia. “How Do Black People with Cancer View Clinical Research?” November 15, 2024. National Cancer Institute. https://www.cancer.gov/news-events/cancer-currents-blog/2024/black-patients-beliefs-clinical-medical-research",
                "Hussin, N. M., S. Shahar, N. I. M. F. Tang, W. Z. W. Ngah, S. K. Das. “Efficacy of fasting and calorie restriction (FCR) on mood and depression among ageing men.” The Journal of Nutrition, Health, and Aging. 17 (8), 2013, pp. 674-80. https://pubmed.ncbi.nlm.nih.gov/24097021/",
                "Onuoha, Mimi. “The Library of Missing Datasets.” https://mimionuoha.com/the-library-of-missing-datasets-v-20.",
                "Unicef. “Women and girls bear brunt of water and sanitation crisis.” UNICEF-WHO report. 5 July 2023. https://www.unicef.org/press-releases/women-and-girls-bear-brunt-water-and-sanitation-crisis-new-unicef-who-report"
              ],
              "images": [
                {
                  "url": "/images/NEVEN_FINAL.png",
                  "caption": "An illustrative image",
                  "alt_text": "Image showing zine artwork"
                }
              ]
            }
          },
          {
            "id": "xiangying-fang-title-tba",
            "title": "FEMININITY IN SERVICE AI",
            "subtitle": "The Digital Reinscription of Gendered Emotional Labor",
            "author": {
              "name": "XIANGYING FANG",
              "email": "fangx339@newschool.edu",
              "bio": ""
            },
            "content": {
              "body": "Service AI systems like Alexa and Siri have become central to daily life, assisting with tasks from setting reminders to providing information. Yet, while these tools represent technological advancements, they also mirror and reinforce gender stereotypes, especially around labor.<br><br>It strikes me how service AIs reinforce traditional gender roles, embodying femininity in subservient, \"helpful\" capacities. These systems, by defaulting to female voices and a deferential persona, perpetuate outdated norms of politeness and compliance. Why do we find it \"natural\" for these supportive roles to be filled by a feminine voice that remains calm, polite, and accepting regardless of treatment?<br><br>In this article, I aim to unpack the layers of cultural, social, and design choices contributing to this trend, examining how these biases are reinforced—and how they might be addressed, and propose inclusive redesigns for service AI to model healthier, boundary-respecting interactions.<h3>The Feminization of Service AI: A Legacy of Gender Norms</h3>From the outset, tech companies anthropomorphized digital assistants with female voices, names, and personalities, aligning with longstanding gender norms where women are expected to be supportive and nurturing. This feminization feels \"natural\" because of embedded cultural associations: women, often cast in administrative or caregiving roles, are perceived as approachable and sympathetic.<br><br>The first notable instance of  digital female assistant voices voices being deliberately used in digital technologies dates back to the mid-20th century with the development of automated systems like Bell Labs’ Voder in the 1930s and 1940s. While the Voder was a general speech synthesis machine, early applications of synthesized speech often featured feminine tones due to perceptions that women’s voices were more pleasant and reassuring for users. This trend continued with the rise of IVR (Interactive Voice Response) systems in the 1970s and 1980s, where female voices became the norm for automated call centers, aligning with stereotypes of women as caretakers and communicators​<br><br>These norms are deeply rooted in Western and global perceptions of gender. For instance, Amazon's Alexa and Apple's Siri were designed with female voices because user testing revealed people responded better to these tones, which were seen as more \"supportive\" and \"trustworthy\".​ Research supports these choices. Studies, like those by Nass et al., show that users respond favorably to female-voiced assistants, associating them with helpfulness and supportiveness, which are culturally aligned with stereotypical feminine traits. Despite AI’s neutrality, users anthropomorphize it, projecting their biases and casting it into roles of emotional labor.<br><br>This emotional labor is reinforced as female-presenting AIs often respond politely, even in the face of rudeness. By engineering subservient female voices into AI, designers perpetuate the expectation that women, like AI, should absorb frustration without pushing back—reflecting real-world biases.<h3>Passive Politeness: The Enforcement of Submissive Communication</h3>A key aspect of feminized service AI is its consistent politeness, even in response to hostility. This deferential style, especially when assigned to a feminine voice, reinforces societal expectations for women to communicate with restraint and avoid confrontation.<br><br>Consider common interactions with these assistants. Commands are met with cheerful responses like “Certainly!” or “How can I help?” even if the user’s tone is curt or disrespectful. Siri and Alexa remain polite and accommodating, enforcing “digital passive aggression” by requiring politeness even in the face of disrespect. Digital assistants like Alexa often respond politely, even in disrespectful situations. An example includes Alexa replying with \"I’m sorry, I didn’t catch that\" when a user makes rude or sarcastic comments. This programming reinforces the expectation that the assistant—and by extension, women—should remain subservient and accommodating regardless of tone​. This non-assertive style reinforces real-world expectations, where women are socialized to communicate agreeably.<br><br>Feminized AI’s polite responses reinforce the stereotype of women as naturally agreeable. Studies, like Abercrombie et al.’s Alexa, Google, Siri: What Are Your Pronouns?, show people generally respond to female voices in AI as they would to women, expecting sensitivity and “soft” communication. Such expectations risk shaping user perceptions of real-world interactions with women.<br><br>Psychological studies have supported these observations. For instance, research on user interactions with voice-based AI reveals a preference for female voices in non-stressful or emotionally engaging tasks, reinforcing the stereotype that women are better suited for nurturing or supportive roles. Conversely, male voices tend to be preferred in high-pressure scenarios, reflecting a bias associating men with authority and technical proficiency. Humans are prone to treating computers as social actors, . They perform experiments showing that people apply social rules to their interactions with computers, such as engaging in behaviors that they would typically reserve for human social interactions like politeness, compliance, and deference, that they would typically reserve for human social interactions. For example, people often respond more positively to AIa voices that areis calm and polite, assuming the AI is \"friendly\" or \"helpful,\" even if it's just programmed to respond in certain ways.<h3>Digital Emotional Labor: AI as a Virtual Caregiver</h3>A striking feature of feminized AI is its role in emotional labor, much like women in caregiving roles. Female-voiced AIs “manage” users’ emotions, responding sympathetically or humorously to rude remarks, reflecting societal expectations that women absorb negativity while maintaining harmony.<br><br>For instance, Alexa has programmed responses to flirtatious or sexist comments, often deflecting with humor. This design mirrors real-world norms that women should deflect inappropriate behavior while maintaining composure. Thus, feminized AI is expected not only to perform tasks but to manage social dynamics, keeping interactions smooth and conflict-free.<br><br>The UNESCO report I'd Blush if I Could addresses this dynamic, noting how AI design reinforces gender norms by assigning emotional labor to female voices. When female-voiced AI responds non-confrontationally to negative comments, it mirrors the societal expectation for women to avoid conflict and passively absorb emotional burdens. In embedding these traits, tech companies endorse gendered expectations, reinforcing emotional labor as intrinsic to femininity.<h3>Social Consequences: Reinforcing Gendered Expectations in Real Life</h3>The feminization of emotional labor in AI doesn’t exist in isolation; it influences user perceptions and potentially how they interact with real women. By interacting with AI that exhibits “ideal” feminine traits—politeness, emotional resilience, and availability—users may begin expecting similar behavior from women they encounter. Feminized AI thus risks setting restrictive standards, subtly suggesting women should embody resilience, politeness, and support.<br><br>Sociological studies have examined this spillover effect. For instance, Robertson’s The Female Persona in AI explores how feminized AI subtly encourages users to treat AI—and by extension, women—as subservient. These implications are significant: as feminized AI becomes embedded in daily life, it risks perpetuating biases that affect real-world social norms.<br><br>Further, female-voiced AI rarely displays assertiveness or boundaries. This cultural expectation that women remain supportive and agreeable, especially in service roles, becomes a default assumption users may apply outside digital contexts. Feminized AI could thus reinforce restrictive gender roles in real-world interactions.<h3>Redesigning Service AI: Toward Inclusive Solutions</h3>To counteract these biases, AI design must be inclusive, offering options that defy gender norms. Non-binary or gender-neutral voices, like the Q – The Genderless Voice Assistant, challenge binary gender norms, offering users choices beyond traditional masculine or feminine voices.<br><br>Rethinking emotional labor in AI could also lead to progress. Instead of programming AI with stereotypically “feminine” responses, developers might try assertive responses that model healthier boundaries. For example, rather than deflecting inappropriate comments with humor, AI could respond with neutrality or direct redirection, reducing the risk of reinforcing submissive expectations. These design changes would promote fairer, more realistic portrayals of service roles and gender.<br><br>Additionally, transparency in AI development can help users understand how design choices affect interactions. When users recognize that politeness and emotional labor are designed traits—not intrinsic qualities of “feminine” AI—they may become more aware of their biases. I'd Blush if I Could advocate for such transparency, suggesting that informed users are better positioned to question embedded stereotypes.<h3>In Conclusion: Toward Balanced, Unbiased AI</h3>As I delve into the dynamics of feminized service AI, it becomes clear this isn’t merely about convenience. It’s a reflection of how we view gendered labor and identity. Service AIs like Alexa and Siri, designed with feminine, subservient traits, mirror societal expectations that women should handle emotional labor, remain pleasant, and manage discomfort.<br><br>By designing AI to embody passivity and emotional labor, tech companies unintentionally reinforce gender stereotypes, influencing user expectations in digital and real-life interactions. Addressing these issues is essential for creating fairer AI and challenging restrictive gender norms affecting women on a broader scale.<br><br>The future of AI lies in inclusive, thoughtful design—one that values diversity and encourages users to question their own biases. By offering gender-neutral options, creating assertive response protocols, and promoting transparency, the tech industry can lead the way in redefining AI’s relationship to gender. As we reimagine AI free from restrictive gender expectations, we open the door to a more equitable digital world where every user feels represented and respected.<br><br>",
              "works-cited": [
                "West, M., Kraut, R., & Chew, H. E. (2019). I'd Blush if I Could: Closing Gender Divides in Digital Skills Through Education. UNESCO. Available at: UNESCO Digital Library.",
                "Costa, P., & Ribas, L. (2019). AI Becomes Her: Discussing Gender and Artificial Intelligence. Technoetic Arts, 17(2), 151-161. DOI: 10.1386/tear_00014_1.",
                "Abercrombie, G., Cercas Curry, A., Pandya, M., & Rieser, V. (2021). Alexa, Google, Siri: What Are Your Pronouns? Gender and Anthropomorphism in the Design and Perception of Conversational Assistants. arXiv preprint. Available at: arXiv.",
                "Vice Media Group. Q – The Genderless Voice Assistant. Copenhagen Pride. Available at: Genderless Voice.",
                "Nass, C., & Brave, S. (2005). Wired for Speech: How Voice Activates and Advances the Human-Computer Relationship. The MIT Press.",
                "Rossen, J. (2020). \"Why Do Virtual Assistants Like Siri and Alexa Traditionally Have Female Voices?\" Mental Floss, 9 May 2020, https://www.mentalfloss.com/article/624227/why-do-virtual-assistants-siri-and-alexa-traditionally-have-female-voices."
              ],
              "images": [
                {
                  "url": "/images/XIANGYING_FINAL.png",
                  "caption": "An illustrative image",
                  "alt_text": "Image showing zine artwork"
                }
              ]
            }
          },
          {
            "id": "amy-lewis-title-tba",
            "title": "Amy Title TBA",
            "author": {
              "name": "AMY LEWIS",
              "email": "lewia046@newschool.edu",
              "bio": ""
            },
            "content": {
              "body": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Praesent tristique, massa sit amet imperdiet ullamcorper, tortor turpis eleifend quam, ac blandit arcu felis ac arcu. Vivamus ac mi vitae neque scelerisque porttitor. Proin porta pharetra velit non luctus. Quisque vulputate porttitor sapien in sagittis. In sit amet justo urna. Praesent purus sapien, convallis id egestas eget, consectetur dictum justo. Nullam tincidunt ipsum faucibus ipsum lobortis laoreet. Nulla sagittis blandit dolor ut commodo. Maecenas hendrerit nisl at sapien finibus faucibus. Aliquam dolor odio, molestie sit amet condimentum a, efficitur vitae enim.<br><br>Fusce maximus mi vel sapien sagittis, eu convallis velit accumsan. Suspendisse maximus varius nulla, ac sodales elit porta et. Praesent mattis aliquam metus, eu lobortis metus rutrum id. Nulla pharetra lectus eget sem pulvinar, quis interdum ipsum tempus. In mattis mauris odio, sed auctor libero finibus varius. Cras non turpis finibus, vehicula nibh non, dictum est. Proin in ipsum id justo tincidunt feugiat id vel justo. Mauris vitae diam vitae diam tristique euismod. Suspendisse arcu ante, consequat eget dictum pretium, eleifend a lorem. Suspendisse in pellentesque mauris. Nunc varius libero blandit ante viverra maximus. Pellentesque pretium, libero non ultricies elementum, lacus massa condimentum mi, eget ultricies arcu elit quis eros. Proin mollis, quam eu interdum tempus, augue nisl efficitur lacus, quis porttitor lectus ex sed dui.<br><br>Mauris tincidunt enim eu tortor sagittis egestas. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Interdum et malesuada fames ac ante ipsum primis in faucibus. Donec mauris turpis, egestas ac leo vitae, porta laoreet mauris. In posuere porttitor purus ac eleifend. Sed cursus lectus tristique iaculis suscipit. Proin varius magna tellus, vitae volutpat elit tempor viverra. Duis vitae libero elit. Nunc auctor purus fringilla arcu ullamcorper, non imperdiet ante mattis. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Pellentesque feugiat fringilla quam, ac maximus tortor auctor quis. Sed dictum purus turpis, ac ullamcorper lacus tempor ut. Praesent et diam tincidunt, ultrices arcu eget, bibendum odio. Sed posuere viverra efficitur. Praesent cursus tempus lectus, sit amet faucibus nisl consectetur eget. Cras imperdiet nulla at ipsum eleifend aliquam.<br><br>Phasellus non volutpat justo. Vestibulum at dignissim libero. Proin justo ex, volutpat maximus blandit pellentesque, ultricies ac ex. Phasellus viverra dolor sem, eu volutpat arcu porttitor eget. Vivamus ac purus tristique, varius ex eget, tempor massa. Mauris auctor diam non risus lobortis, nec imperdiet nibh dapibus. Nullam efficitur imperdiet augue, in tempus magna. Aliquam eu elit sed urna commodo facilisis ut sed sapien. Mauris sodales varius lectus et maximus. Donec a purus et turpis iaculis porta. Pellentesque elit est, laoreet nec dolor in, vulputate ultrices orci. Quisque lobortis sodales metus eget suscipit. Mauris tempus sem nec nulla tempor interdum. Nam congue consectetur enim, vel aliquam est convallis vel. Curabitur erat urna, hendrerit vel magna et, aliquet placerat sem. Phasellus eget leo sed nibh aliquet aliquam.<br><br>Curabitur in orci dolor. Duis volutpat ipsum tortor, eget fringilla est venenatis non. Duis mollis erat nibh, id sollicitudin nisi dapibus in. Nulla facilisi. Nam eros lectus, sagittis sed justo faucibus, blandit mattis diam. Mauris pharetra volutpat sollicitudin. Nulla vitae ligula at neque bibendum vehicula. Integer bibendum ante quis mollis venenatis. Curabitur ut arcu in nibh condimentum tempor. Duis a hendrerit lacus, sed ultricies orci. Suspendisse finibus, velit nec tincidunt ultrices, metus odio semper est, et feugiat eros lorem id ligula. Donec nec tellus volutpat, facilisis dolor nec, euismod magna. Aliquam mattis diam sapien. Nunc a magna eu augue pretium euismod sit amet eu nibh. Duis augue tortor, mattis scelerisque sagittis ac, bibendum nec leo.",
              "images": [
                {
                  "url": "/images/AMY_FINAL.png",
                  "caption": "An illustrative image",
                  "alt_text": "Image showing zine artwork"
                }
              ]
            }
          }
        ]
      },
      "surveillance-and-the-media": {
        "id": "surveillance-and-the-media",
        "section-title": "Surveillance & The Media",
        "articles": [
          {
            "id": "viviane-ma-title-tba",
            "category": "Surveillance & The Media",
            "title": "THE CULTURE GAP ON SOCIAL MEDIA",
            "author": {
              "name": "VIVIANE-YUERONG MA",
              "email": "may770@newschool.edu",
              "bio": ""
            },
            "content": {
              "body": "How often do you come across reposted content on social media that are from another country? Do you ever look at the comment section, trying to find someone who answers your question or holds the same opinion as you? Whether it is X (Twitter), Instagram, TikTok, or any other platforms, social media is so efficient at delivering unlimited and even ‘exotic’ contents to your devices.<h3>Those That Catch the Viewers’ Eyes</h3>Being a social media influencer seems to be one of the easiest ways to grow your own career in today’s time. There is almost no budget required to start your own account, and unlike some countries that may require you to upload proofs of your identity, you can simply register on most sites in the United States with a click of a button, or several buttons at most. Growing up as a Gen Z, influencers also made up many of my fellow classmates’ conversations in high school. You do not need to go fish for the news on Google, TikTok will bring you the hottest trends and controversies after a few swips. In October 2021, confidential data on Twitch streamers’ salaries leaked online, exposing the payouts received by some of the biggest streamers on the internet. The popular Dungeons and Drangons channel, CriticalRole, earned $9,626,712.16 from August 2019 to October 2021; and individual streamers like xQcOW earned up to $8,454,427.17 with that time span. With that much profit, it is with no doubt that youngsters may lean towards a path within the industry of social media. But what does it take to shine through so many ‘wannabes’? To do things completely out of your comfort zone and pull on stunts for the views, maybe.<br><br>Mukbang, a popular live genre which usually involves the streamer to consume various quantities of food, became popular in the 2010s. From eating while chatting with viewers, it soon became sensational - to stand out from thousands of Mukbangs, you either eat more, or eat weird. There are obviously critics that comes with the fame. Food waste and fake eating were the main problems. It got to a point where the Chinese video streaming site, Bilibili, starts showing “eat responsibly” when viewers search for videos containing the word “Chi Bo” (Mukbang in Chinese) or “Da Wei Wang” (People who are able to eat large quantities of food). Today, the trend of Mukbang has gone out of sight, but there is still a constant fan base, and to achieve success through eating, you have to go even more extreme.<br><br>As a daily scroller myself, I often find myself in a loophole of strange videos on Instagram of people consuming non-edible looking foods, and a lot of times, it is by someone who is Chinese. These videos are reposted by attention farming accounts for the pure purpose of getting views and followers. Frankly, since hashtagging is a main portion of incoming views, it does not matter if the original video is actually from China or Korea, or other places, because the people will believe what they see. It is also important to note, that a lot of these videos are considered to be strange, even to Asians, and is a unrealistic capture of the lifestyle of Asian people. With different cultural backgrounds, viral videos usually get many backlashes, from the looks of the foods, to the way people consume them. This is not limited to Mukbang, and it is not limited to Western social media.<h3>Pro-Western and Anti-Western</h3>As I became more involved with my own cultural background, I found myself suck in a middleground, belonging to neither the western nor the Chinese community in the way I thought I would fit in.<br><br>The Little Red Book (Xiao Hong Shu) is a Chinese social media platform that is a mixture of Pinterest and Instagram, not only in its functionality, but also the contents within. Going back to our topic of Mukbang, as the Asian originated genre became viral internationally, many western creators have also picked up the gist and started their own version of the eating show. Similar to the the small portion of Asian Mukbang that received hate from other communities, attention farming accounts in China have also reposted videos from the Western media, usually the extreme ones that clearly is a portrayal of a minor community and shows vast differences from the Asian culture, for the purpose of raising arguments between Asian and Western communities.<br><br>One of the viral accounts on the Little Red Book is famous for reposting videos from an Instagram account named mamaj.rae, which is a mom posting daily meal preparation videos of a lower middle class family with seven kids. On the reposter’s profile biography, they claim to be a repost account for western food culture, sharing delicious food videos to others. With a total of 26.1k followers, the account only reposts mamaj.rae’s videos after finding initial success in July 2024, and each post has around 1000 likes, with the most popular video having 27.1k likes. The purpose of the account might be for entertainment only, but in a country with such massive population as China, it is hard for everyone to be at the same level of education, and definitely have not everyone been to foreign countries. With that being said, many comments are targeting the way the food is being cooked, whether the vegetables have been washed properly, or doubting the stereotypes of western culture that have been ingrained in Asian countries.<div class=\"image-container\"><img src=\"/images/VIVIANE_IMAGE1.jpg\"/></div>Of course, the food section of social media is not the only problematic part, but it shows how miss-information can be spread so easily using social media. Despite China blocking western media to prevent harmful government activities, most citizens do have ways around it, using VPNs to access the world outside of China. With that being said, people can definitely search up the truth and learn more about other cultures. Although, even though it is hard to admit, the pride within individuals are prone to keep the truth out, making absurd assumptions to be more believable. However, as the younger generations, it is our responsibility to be more mindful and patient with the information we intake, to differenciate the entertainment and the credible.<br><br>",
              "images": [
                {
                  "url": "/images/VIVIANE_FINAL.png",
                  "caption": "An illustrative image",
                  "alt_text": "Image showing zine artwork"
                }
              ]
            }
          },
          {
            "id": "nathan-williams-title-tba",
            "category": "Surveillance & The Media",
            "title": "SELF-EXPOSURE",
            "author": {
              "name": "NATHAN WILLIAMS",
              "email": "willr520@newschool.edu",
              "bio": ""
            },
            "content": {
              "body": "“The transformation of the television into a low-end computer monitor, or to inverse the terms; the portable computer into a video monitor, effectively transforms a personal, domestic device into an apparatus of behavior control, a post allowing us to see, in the very same moment, whatever is happening around the globe. But there is a price, which is to agree in return (in a counter-image) to be ourselves visually controlled, and now not only by institutions specializing in investigation, whether police or military surveillance, but by anybody and everybody.”<br><br>Images have historically been the primary sources that we look to in order to find understanding and meaning behind human experience. We believe them to be truthful and reliable ways to represent certain aspects of our nature and, through our understanding of them,  create a more certain and confident self. Defined as “a reproduction or imitation of the form of a person or thing”, an image encapsulates how information is received, processed, and recorded by human beings. As Baudrillard claims, “Thus perhaps at stake has always been the murderous capacity of images: murderers of the real; murderers of their own model as the Byzantine icons could murder the divine identity.”<br><br>In our contemporary age of information overload, it is obvious that images are not as truthful and reliable as we have seemed to believe in the past, especially with new and emerging technologies like AI image making models and machine learning networks that can generate accurate deep fakes. These technologies allow a level of accessibility to image sources that we have never seen before, in which information surrounding an image can be found at the click of a button. Although we have become used to this capability in our age of information overload, what we have yet to understand or really bring attention to is how humans have shifted from becoming image consumers to image purveyors. According to a 2024 Pew Research Study on American’s Social Media Usage, 68% of U.S. Adults use Facebook, 47% use Instagram, and 33% use Tik Tok. These platforms emphasize content creation, resulting in a meteoric rise of personal visual contributions. Although users are not forced to post on these platforms, without image purveyors, there would be no appeal. If images are becoming less trustworthy, more accessible, and easier to create and distribute on an individual level, the way that we understand ourselves through them will likely change too.<h3>Images have changed from existing as references we observe to becoming vehicles of validation that we craft,  shaping our  self-image and understanding of identity.</h3>Surveillance technologies serve as a medium to craft our understanding of identity through personal image creation. Features like the camera, GPS, and microphone work together, allowing us to develop a curated image that we project into the world. Through this process of seeking self-understanding, the image validates us. Although it is important to note that surveillance technologies can be used for malicious purposes, they also hold an important and inarguable role in shaping the way that users of digital platforms perceive themselves, whether good or bad. A “more nuanced and productive portrait of this transition than doomsday scenarios offer” is needed, and if “this architecture truly breaks with Foucaldian discipline, we could justly wonder whether it should still be characterized as panoptic.” Should we condemn this panoptic age outright if so many of us utilize surveillance technologies to relate to, validate, inform, and respond to others in order to better understand our place in the world?<br><br>Exhibitionist art offers a way to explore how a shift from image consumerism to image purveyance through the use of surveillance technologies has allowed people to explore  personal identity. For instance, Jill Magid’s “Evidence Locker” explores the process of receiving one’s image through a surveillance technology that is held by an enforcing power, which she then edits and stages. Through developing a relationship between herself and the enforcing power, she uncovers how she is perceived in public space as well as through the lens of a surveillance power. Similarly, Wafa Bilaal’s “Domestic Tension” explores how broadcasting and viewership influence behavior, especially when it comes to the identity of the surveyed. Viewers hidden behind a camera have the ability to control his experience, serving as a metaphor to the treatment of Iraqi Americans in Post-9/11 America. Furthermore, Jennifer Wringley’s “Jennicam” was a pioneering experiment which dubbed her the first “camgirl,”sparking outrage surrounding exhibitionism and online presence. These artworks have brought about interesting concepts, particularly that of “disruptive exhibitionism”, which “offers a way for marginalized identities and bodies to engage with visibility, where public visibility may be difficult or even dangerous.” Engaging with exhibitionist artworks can reveal the intentions and revelations that individuals experience when interacting with surveillance technologies, particularly when it comes to the exploration of their own identity. These engagements are important in navigating and understanding our current state, where these technologies are the way in which we understand how to exist and perceive the world around us.<br><br>",
              "works-cited": [
                "Baudrillard, Jean. Simulacra and Simulation. Trans. Sheila Faria Glaser. Ann Arbor: University of Michigan Press, 1994.",
                "Chan, Julia, and Stéfy McKnight. “Disruptive Exhibitionism - a Performance Methodology for Surveillance Art.” Media Practice and Education 24, no. 2 (2023): 162, Routledge.",
                "Gottfried, Jeffrey. “Americans’ Social Media Use.” Pew Research Center, January 31, 2024. https://www.pewresearch.org/internet/2024/01/31/americans-social-media-use/.",
                "Merriam-Webster.com Dictionary, s.v. “image,” accessed December 10, 2024, https://www.merriam-webster.com/dictionary/image.",
                "Russo, Julie Levin. \"Show Me Yours: Cyber-Exhibitionism from Perversion to Politics.\", Camera Obscura 25, no. 1 (2010): 136. Durham: Duke University Press.",
                "Virilio, Paul. “The Visual Crash.” In Rhetorics of Surveillance From Bentham to Big Brother, edited by Thomas Y. Levin, Ursula Frohne, and Peter Weibel. The MIT Press, 2002."
              ],
              "images": [
                {
                  "url": "/images/NATHAN_FINAL.png",
                  "caption": "An illustrative image",
                  "alt_text": "Image showing zine artwork"
                }
              ]
            }
          },
          {
            "id": "elektra-fischer-title-tba",
            "category": "Surveillance & The Media",
            "title": "PRIVACY IN AN OBSERVED WORLD",
            "author": {
              "name": "Ekektra Fischer",
              "email": "fiscs731@newschool.edu",
              "bio": ""
            },
            "content": {
              "body": "When I set out to write this piece, I realize now, I was under a few misconceptions. Firstly, I was under the impression that South Korea was considered a high surveillance state, and that the US was not. This understanding was due to the large presence of CCTV cameras I observed while on a trip  in South Korea in comparison to the less ubiquitous security cameras I’ve noticed used in the US. However, tThrough research and reflection, I have learned that, conversely, the US is considered a high surveillance state due to its prolific use of security cameras, facial recognition technology, and data collection while South KoreaK is not. Due to the increase of security cameras, facial recognition, and data collection the US is considered to be bordering on a high surveillance state. The US is even considered to have CCTV. Essentially, this changes a lot of what I initially intended to write, but the conversation is the same. <h3>Privacy in an Observed World</h3>What does privacy look like in a state of constant surveillance? Do your actions change when you are being observed? Is there room for mistakes when everything is known? At what point does surveillance become harmful?  These are some questions that arise when I reflecting on the increased use of surveillance globally? In the US?.<br><br>Prior to visiting South Korea, I was aware of itsthe high degrees of surveillance, but from a predominantly positive perspective. Many internet creators have made videos discussing just how safe Korea is, citing cases of petty theft that were resolved within 24 hours due to CCTV. Considering the previously high rates of crime where? In the US?, I thought  highly of such security. In the US there has been an increase in surveillance, to the point where now we are considered to have CCTV (Closed-Circuit Television) similarly to South Korea and the United Kingdom.<br><br>My personal experience with CCTV in South Korea is limited to the three weeks in total I have spent in South Korea (and apparently living in the US), mostly in Seoul with a few nights in Jeju. After feeling empowered one evening, a  friend and I took it upon ourselves tous to go swimming sansregardless of our lack of garb. This led to skinny dipping at –arguably– not the most secluded beach on our first night in Jeju. In hindsight, I shouldmight have been pickier about our choice of location, but overall,  I do not regret my actions. There are few experiences that compare to being in the ocean with no degree of separation between one and the cockles. However, there is something to be said considering about time and place. After entering the water,  was when I noticed a the camera on the far  a nearby lightpost.<br><br>To me, the act of skinny-dipping seemed relatively is harmless to a degree. I understand why it is not commonplace, but I don’t agree with it being completely outlawed either. In many cultures, I would go as far as to say that such an act is normalcommonplace, even if this might not be the case where I’m from in the US. In the USStates, I would describe the perception of skinny-dipping as is typically considered something that young people do in secluded places to be rebellious, etc. In my case, would say I was simply trying to be spontaneous and enjoy the opportunities afforded to me.<br><br>It was not until months later that I realized the the full weight of my actions occurred to me, when I learned that. I I’d openly broken a law on CCTV in one of the most surveilled places I have been to. At thethis time, I began to question if I could ever return to South Korea considering the circumstances. This, in turn,Thus, I started a much larger internal dialogue within me about the implications of surveillance.<br><br>Are the affordances of surveillance worth the cost? Where is the line drawn, and what freedoms are -or are not- essential, or worthy? What would it look like to live in a place where there is no room for error, no individualism, nor exploration? Personal freedoms come in many forms and look different for many. I think the reason why this topic was interested tointerested me to explore this topicis in order to grapple with the because of the central question of what personal liberties are worth affording. In the US, we have the large perception that adolescence is the time in one’s life where one makes many mistakes and learns from them. We are reckless, blatantly stupid, and driven by a low impulse control. We have an entire subgenre outlining this phenomenon labeled coming of age. Obviously, this is not an exclusively American phenomenon. We do not have a monopoly on youthful foolishness, but maybe our individualistic society provides more breathing room for this.<br><br>It is difficult for me to imagine growing up somewhere that prohibits youthful error. I made an obscene degree of mistakes when I was growing up, and still do. In my opinion, skinny dipping is not a mistake;, it is a rebellious act that offers refuge from monotony. I would prefer to live somewhere that encourages such acts ratheracts, not rather than inhibits them. I know that surveillance has many purposes, but how it is used comes down to specific instances. Aas we expand the use of surveillance equipment in the US, I think it is crucial to be prudent about its use. While the law and surveillance, theoretically, are intended to ensure our safety, it is necessaryintegral that we do not remove all understanding of error. We are human., Wwe falter., Iit is our way. Of course, people will try to take advantage of this, but I would rather live in a world where one must be vigilant about such individuals than one that removes any room for error.<h3>Acknowledgement:</h3>Of course this degree of room for error looks different for everyone in the US depending on their race, ethnicity, sex, abilities, queerness, and socioeconomic status. Many in the US already live with no margin of error afforded to them. This should not be the case for anyone, and until we experience substantial police reform, we cannot expect real change.<br><br>",
              "images": [
                {
                  "url": "https://example.com/image1.jpg",
                  "caption": "An illustrative image",
                  "alt_text": "Image showing zine artwork"
                }
              ]
            }
          },
          {
            "id": "fatima-ashraf-title-tba",
            "category": "Surveillance & The Media",
            "title": "FROM GOD TO ALGORITHMS",
            "author": {
              "name": "FATIMA ASHRAF",
              "email": "ashrf576@newschool.edu",
              "bio": ""
            },
            "content": {
              "body": "The concept of panopticism has evolved from Jeremy Bentham’s 18th-century prison design to a broader framework that governs modern behavior. Bentham’s Panopticon, a circular prison with a central tower for guards to observe inmates without being seen, was revolutionary in its ability to maintain order through the perception of constant surveillance. Michel Foucault expanded this idea, suggesting that the panoptic structure was not limited to physical spaces but extended into society at large. He argued that modern institutions, from schools to workplaces, employ similar mechanisms to discipline individuals, making them internalize the gaze of authority. This internalization ensures compliance, not through physical enforcement but by cultivating the belief that one’s actions are always being watched and judged. This psychological effect has parallels in religious traditions that emphasize the omnipresence of a Divine Being.<br><br>Religious teachings across cultures reinforce the notion of an unseen observer, shaping moral and ethical conduct. Christianity, for instance, portrays God as an omniscient and omnipresent being, as reflected in Proverbs 15:3: “The eyes of the Lord are everywhere, keeping watch on the wicked and the good.” Similarly, in Islam, the Quran frequently describes Allah as “Al-Baseer,” the All-Seeing, observing every action and thought. These religious frameworks establish an internalized discipline among believers, who modify their behavior to align with moral codes, fearing divine retribution or seeking reward in the afterlife. The parallels to Bentham’s Panopticon are striking—just as prisoners cannot see their observer but believe in their presence, adherents of religious faith accept the unseen gaze of God as a guiding force in their lives.<br><br>Modern digital surveillance extends this dynamic into the technological age, transforming the observer from a deity to an algorithm. Shoshana Zuboff’s analysis of surveillance capitalism highlights how corporations like Google, Facebook, and Amazon monetize personal data, creating systems that track and predict human behavior. This form of surveillance is often accepted because of the conveniences it offers, such as personalized recommendations and enhanced security. However, the psychological effect mirrors religious conditioning. For example, a 2021 Pew Research Center study revealed that 70% of Americans use social media platforms despite concerns about data privacy, indicating a trade-off between privacy and perceived benefits. Users often engage in self-censorship and meticulously curate their online personas, anticipating scrutiny from peers, employers, or unseen authorities. This behavior aligns with Sarah Kendzior’s findings that the anticipation of being watched leads individuals to act in ways they believe will be socially acceptable, much like religious adherents striving to meet moral expectations.<br><br>Governments and corporations have also adopted panoptic methods to maintain control and order. In China, the social credit system exemplifies the fusion of surveillance and societal regulation. This system monitors citizens’ behaviors, assigning scores that determine access to services, jobs, and even travel. A low score can result in severe penalties, effectively conditioning individuals to conform to state-sanctioned norms. Similarly, in Western democracies, revelations such as Edward Snowden’s disclosure of the NSA’s PRISM program have shown how governments use surveillance to monitor global communications. Despite public outcry, these programs persist, reflecting society’s ambivalence toward the trade-offs between privacy and security. A 2020 survey by Ipsos found that 58% of respondents across 28 countries supported government surveillance for counterterrorism efforts, even if it meant sacrificing some personal freedoms.<br><br>The private sector also plays a significant role in normalizing surveillance. Companies like Amazon have integrated panoptic principles into everyday life through products like Ring doorbell cameras. Marketed as tools for home security, these devices enable neighborhood-wide surveillance networks, turning ordinary citizens into watchers. This phenomenon not only reinforces the perception of constant observation but also cultivates a sense of safety, akin to the comfort derived from religious beliefs in a protective deity. A 2022 report by Deloitte found that 75% of consumers trust technology companies to handle their data responsibly, despite the prevalence of data breaches. This trust mirrors the faith many have in religious systems, even in the absence of tangible proof of their fairness.<br><br>The political implications of digital surveillance are profound, particularly in authoritarian regimes where it is used to suppress dissent. During the 2020 protests in Belarus, activists reported being identified and arrested through facial recognition technology, demonstrating how surveillance can stifle opposition. In democracies, the effects are subtler but equally significant. Social media platforms, equipped with sophisticated algorithms, can influence public opinion and behavior by amplifying certain narratives while suppressing others. This power to shape societal norms and expectations underscores the enduring relevance of panopticism as a tool for control.<br><br>Religious conditioning has eased society’s acceptance of modern surveillance, making the concept of being watched seem natural, even comforting. For centuries, belief systems have associated observation with order and morality, a framework that digital surveillance seamlessly integrates. Real-world surveys and studies reinforce this connection. For example, a 2023 study published in Computers in Human Behavior found that individuals who grew up with strong religious beliefs were more likely to accept surveillance technologies as beneficial. This finding suggests that the internalized discipline fostered by religious teachings carries over into the digital realm, where surveillance systems are perceived as necessary for maintaining societal order.<br><br>The parallels between religious and digital surveillance reveal a shared purpose: the regulation of behavior through observation. In both systems, the observer holds power by being invisible yet ever-present, creating a sense of accountability among those being watched. This dynamic has shaped human behavior for centuries and continues to evolve in the digital age. While the tools and actors have changed, the underlying principles of panopticism remain constant, illustrating its enduring influence on society.<br><br>",
              "images": [
                {
                  "url": "/images/FATIMA_FINAL.png",
                  "caption": "An illustrative image",
                  "alt_text": "Image showing zine artwork"
                }
              ]
            }
          }
        ]
      },
      "hidden-narratives": {
        "id": "hidden-narratives",
        "section-title": "Hidden Narratives",
        "articles": [
          {
            "id": "nick-lyons-title-tba",
            "category": "Hidden Narratives",
            "title": "(UN)PROTECTED HEALTH INFORMATION",
            "author": {
              "name": "NICK LYONS",
              "email": "lyonn670@newschool.edu",
              "bio": ""
            },
            "content": {
              "body": "Digital health has become commonplace for many healthcare patients, from the daily use of fitness tracking devices daily to advanced health monitoring services from vendors like One Medical. While these advancements provide new and exciting experiences for patients, they can also open the door to data risks related to health information. For years, health information was protected by a federal regulation called the Health Insurance Portability and Accountability Act (HIPAA). These protections are being challenged by new risks that have emerged with digital health advancements.<h3>Covered Entities</h3>Even when HIPAPA was passed in 1996, many healthcare providers did not qualify as covered entities due to the definition highlighted in the regulation. In order to be a covered entity, the provider must conduct electronic transfers as defined by the Department of Health and Human Services. For example, a public school that provides healthcare services only for students is not a HIPAA covered entity because student health information is classified as “education records.”. This highlights athe gaps in current legislation that poses risks to the security of sensitive health information.<h3>Digital Devices</h3>People share sensitive datainformation on digital devices to incorporate data in meaningful ways to promote good health, but that data may be recorded and vulnerable. Some forms of data these devices and applications may be recording include the fingerprints used to unlock phones, face scans from facial recognition technology, and data from fitness and fertility tracking informationers, mental health diagnosesapps, and digital medical records.Recording this data canThis provides valuable insights for consumerscustomers that enable new ways to stay healthy, but some of these digital device companies may be sharing that data with third-parties. The negative impacts of this data sharing could include raising insurance premiums, discriminatingion against applicants for jobs and/  housing, and even enablinge surveillance.<h3>Health Data for Sale</h3>While many people may have some awareness of data exchange of some level, they also may assume that their sensitive health data is under some form of protection. Unfortunately, the various loopholes of data collection actually make it very possible, and even legal, for sensitive health data to be shared or sold through data brokers. As Deborah Serani, author of Living with Depression notes, “While this is quite alarming, all of this is legal and under the general public’s radar. It’s been happening for years and is a long-standing breach that places health information at risk.” <br><br>This information might include diagnoses like depression or prescribed medications, often with patient names and addresses.",
              "works-cited": [
                "Daniel, Lars. 2024. “100 Million Americans’ Medical Records Exposed in Massive Data Breach.” Forbes. October 28, 2024. https://www.forbes.com/sites/larsdaniel/2024/10/28/100-million-americans-medical-records-exposed-in-massive-data-breach/.",
                "Fry, Hannah. 2024. “Tracking Your Health with a Device? Here’s Where the Data Could Go.” Los Angeles Times. November 20, 2024. https://www.latimes.com/california/story/2024-11-20/how-much-does-your-smartwatch-know-about-you.",
                "HIPAA Journal. 2017. “What Are Covered Entities under HIPAA?” HIPAA Journal. October 18, 2017. https://www.hipaajournal.com/covered-entities-under-hipaa/.",
                "Seh, Adil Hussain, Mohammad Zarour, Mamdouh Alenezi, Amal Krishna Sarkar, Alka Agrawal, Rajeev Kumar, and Raees Ahmad Khan. 2020. “Healthcare Data Breaches: Insights and Implications.” Healthcare 8 (2): 133. https://doi.org/10.3390/healthcare8020133.",
                "“Your Mental Health Data Is Being Sold—and It’s Legal.” 2023. Healthline. March 10, 2023. https://www.healthline.com/health-news/your-mental-health-data-is-being-sold-and-its-legal."
              ],
              "images": [
                {
                  "url": "/images/NICK_FINAL.png",
                  "caption": "An illustrative image",
                  "alt_text": "Image showing zine artwork"
                }
              ]
            }
          },
          {
            "id": "katya-danziger-title-tba",
            "category": "Hidden Narratives",
            "title": "POST TRUSH & POLITICS IN THE AGE OF GENERATIVE AI",
            "author": {
              "name": "KATYA DANZINGER",
              "email": "danzk958@newschool.edu",
              "bio": ""
            },
            "content": {
              "body": "Post-Truth—as a recent explosion of political culture in which debate is framed by appeals to emotion disconnected from the details of policy or impartial information—requires a careful examination. Is it political spin, wishful thinking, mass myth, art of evasion, or simple lying, based on “fake news” and “alternative facts?”? Nowadays, There are repeated unverified assertions are repeatedly made  to which factual rebuttals are ignored, and people are compelled to believe them something regardless of evidence. How do these unverified assertions differ from previous examples of political lying especially in the context of our current information age? What makes post-truth different from past political manipulations—including that of propaganda—is communicative abundance.<br><br> This enables messages to be sent and received through multiple user points, in a chosen time, real or delayed, within global networks that are unregulated, affordable, and accessible to billions of people. In this new era of communicative abundance, Marshall McLuhan’s famous formula—the “Medium is the Message”[citation] distributed in a “global village”[citation] without restraint—has reached a new level of boundlessness. The message, is based on a deliverer’s whim, and itself becomes the medium.<br><br>Governments, regulators, and other branches of the state are just not prepared for the potential threat tied to AI now widely being used to spread misinformation. Publicly, lawmakers, tech executives, and outside groups monitoring elections urge caution when dealing with a technology developing faster than it can be controlled. Generative AI and synthetic media pose significant risks of abuse in electoral processes worldwide, and the 2024 election cycle was and has been particularly vulnerable in this regard.<br><br>We are experiencing a panic-stricken information age, undermined and eroded by Big Tech corporations that profit from distorting democracy and amplifying outrage. (Note: A secondary unfortunate byproduct of this business model is the extinction-level threat faced by journalistic institutions, as monolithic and divisive “feeds” replace and defund traditional journalism.) Every day, social media users see only a fraction of what is posted daily on TikTok. And what they do see is highly curated by the company’s automated systems designed to keep people glued to their smartphones. Using machine learning and so-called recommender systems (collaborative and content-based filtering, see NVIDIA’s Glossary), these systems determine within milliseconds what content to display to social media users. This mechanism is what makes our public political discourse more and more extreme as the algorithm is trained to choose conflict and controversy, which light up the feed and attract likes in a way that subtlety and ambiguity never will. Big Tech favors extremism to boost engagement and thus profits.<br><br>The risks of AI-fueled disinformation and algorithmic distortion of our civic debates are everywhere, but they are likely to be even more pronounced in non-Western regions of the world where social media corporations are known to under-invest in safeguards (i.e. Trust and Safety boards largely only exist in the Global North). In authoritarian, rogue, or unstable regimes, bad actors are able to exploit the chaos of the Infocalypse with greater impunity (although no political system or country is immune). Mis and disinformation have been causing chaos and even inciting genocidal violence in places like the Philippines, Myanmar, and India (Indian political parties are estimated to spend over $50 million on AI-generated election campaign material this year)—before the West woke up to the problem with the Russian-led U.S. election interference of 2016.<br><br>Western democracies still have defenses in the rule of law, the free press, and the democratic institutions, all of which are established (even as they become increasingly vulnerable). In countries where there are no institutional safeguards, however, the consequences of the corroding information ecosystem could be even more devastating. Our shared reality is at stake when the Infocalypse is broadly being used to threaten and intimidate domestic opposition, drown out dissenting opinions, incite violence (ethnic and/or gender), and suppress fundamental human rights.<h3>Where We’re Headed</h3>Much of the technical expertise required to make changes to the algorithms to “win” the current information war resides deep within companies. Legislative efforts, including the European Union’s recently- passed Artificial Intelligence Act, are, at best, works in progress. The near total lack of oversight of how social media platforms’ AI-powered algorithms operate makes it impossible to rely on anyone other than tech giants themselves to police how these systems determine what people see online.<br><br>Where I believe we’re heading, though, is a “post-post-truth” era, where people will think everything is made up, especially online. Think “fake news,” but to the utmost extent where not even the most seemingly authentic content on the BBC can be presumed to be 100 percent true. With the hysteria around AI often outpacing what the technology can currently do — despite daily advances — there’s now a widespread willingness to believe all content can be created via AI, even when it can’t. In such a world, it’s rational to not have faith in anything.<br><br>Thirty percent of Americans claim, despite all evidence to the ­contrary, that the last presidential elections were “rigged.”[citation?]. Millions are sure that the “deep state” is plotting to import immigrants to vote against “real ­Americans” in the future. Meanwhile in Russia, the majority of people claim that the Kremlin is the innocent party in its brutal invasion of Ukraine. When Ukrainians call their relatives in Russia to tell them about the atrocities, all too often they hear their own kin parrot the Kremlin’s propaganda lines. Across the world, there has been is a growth of propaganda that promotes an alternative reality where truth is cast away in favor of a sense of superiority and paranoia.<br><br>One thing that we must remember and keep at the forefront of our minds in these debates is that computers don’t make decisions- that it is we, humans, who make decisions, and that these decisions are then amplified by AI. We must generate the buy-in necessary for an effective global regulatory framework through networked and inclusive multi- stakeholder approaches, while acknowledging that self- and voluntary-regulation of the AI industry is an insufficient guarantee for human values centered approaches. AI that is not operated in compliance with international human rights law should be banned or suspended until adequate safeguards are put in place. A first (and perhaps the most obvious) step for policymakers is to begin with ensuring that what is illegal offline, is also illegal online<br><br>",
              "images": [
                {
                  "url": "https://example.com/image1.jpg",
                  "caption": "An illustrative image",
                  "alt_text": "Image showing zine artwork"
                }
              ]
            }
          },
          {
            "id": "anon-title-tba",
            "category": "Hidden Narratives",
            "title": "Anon Title TBA",
            "author": {
              "name": "MY INTRODUCTION TO THE MINECRAFT TO CYBERCRIME PIPELINE",
              "email": "anon@newschool.edu",
              "bio": ""
            },
            "content": {
              "body": "At 11 years old, I first discovered online games, like Minecraft, which became my escape from the small, insular world of Chatham, Massachusetts. Growing up in a town where I’d known the same eighty kids since kindergarten, I longed to escape . Minecraft became my gateway—a place where I could slip into the persona of \"User,\" the fearless leader of my faction. The friends I made online felt as real as any in person, opening my eyes to perspectives I’d never encountered in my everyday life.<br><br>This was the story I shared in my college application  essay, one that helped me gain acceptance to colleges with less than 9% acceptance rates. In that essay, I described how my time online taught me empathy, curiosity, and design, bringing me closer to the person I wanted to become.<br><br>But there was more to that story—parts I left out, not because I was ashamed, but because they felt too raw for a college application. Over the years, I spent roughly 15,000 hours in my room, my family assuming I was just playing Minecraft. In reality, I was interacting with hundreds of people online, some with nefarious intentions like pedophiles and criminals.  These interactions would shape how I saw the world, particularly how power works in a connected, digital society. I was DDosed (Distributed Denial of Service), threatened, and even doxxed, but that wasn't a unique experience for someone playing hardcore factions(HCF) from 2012 to 2018. For all its chaos, this experience became an unconventional education. Despite everything, I am deeply grateful for what I learned.<br><br>This article will both touch on my personal experiences with the Minecraft to cybercrime pipeline and  explore the broader culture of Minecraft’s online world—a world that shaped not only me but also countless others, rippling outward to influence the larger cyber landscape. From DDoS attacks to account hijacking, the knowledge shared among  this community—whether used positively or not—has had lasting effects.<br><br>Doxxing, for example,the practice of exposing someone’s personal information online, seemed like an abstract danger until I became  its target. One day, someone identified my school’s name in a game chat. I couldn’t unsee the message. Someone, somewhere, knew exactly where I was. \"User\" was supposed to be my persona, my shield. But suddenly,  I wasn’t protected—a stranger  not only knew where I attended school but also knew my home address, my parents’ names, everything. Each day, I walked into school with completely chewed through fingernails and anticipated the possibility of hearing my name over the loudspeaker or seeing the police waiting at my school. To my relief, nothing ever came of this, but I remained uneasy for many years.<br><br>I still keep in touch with friends I made online when I was just 11, many of whom, like me, are now on paths to achieving great things in life. While none of us ever crossed any major lines, it’s striking how often I hear about someone we knew—either closely or loosely—being arrested for cybercrimes, with some facing over 25 years in federal prison. Even those cases barely scratch the surface of the cybercriminals who emerged from the HCF community.<h3>Paras Jha - Cybercriminal</h3>Minecraft’s open-ended gameplay and competitive server culture have long-served as fertile ground for experimentation and innovation. For Paras Jha, a Rutgers University computer science major and Minecraft enthusiast, it was more than just a game—it was the starting point for one of the most consequential cyberattacks of the decade.<br><br>Jha’s story is a cautionary tale of how curiosity and technical skill can spiral into something far more disruptive. His early involvement in Minecraft server wars introduced him to DDoS attacks, a tactic often used to overwhelm a rival server with traffic until it crashes. In the high-stakes world of Minecraft servers, where hosting a popular server could mean earning tens of thousands of dollars per month, DDoS attacks became a common tool of sabotage. Jha’s technical expertise led him to create and sell DDoS protection services to server owners—essentially running what prosecutors later described as a high-tech protection racket.<br><br>But Jha’s ambitions didn’t stop at Minecraft. Along with two collaborators, Josiah White and Dalton Norman, he developed the Mirai botnet, a powerful piece of malware that hijacked Internet of Things (IoT) devices—smart cameras, routers, and other internet-connected gadgets—to create a network of hundreds of thousands of compromised devices. With this botnet, the trio launched DDoS attacks on a scale never seen before. One of the most infamous incidents occurred in October 2016, when Mirai was used to attack Dyn, a major DNS provider, disrupting internet access across the United States and taking down websites like Twitter, Netflix, and PayPal for hours.<br><br>The irony of Mirai’s origins isn’t lost on those familiar with Jha’s background. What began as tactics to dominate Minecraft servers—crippling competitors and securing a larger player base—evolved into attacks targeting critical internet infrastructure. Mirai’s ability to exploit IoT devices exposed a glaring vulnerability in modern technology: the lack of basic security measures in the rapidly growing ecosystem of connected devices.<br><br>Even before Mirai, Jha made headlines for his attacks on Rutgers University’s computer network, where he was a student. Using the alias “exfocus,” he launched a series of DDoS attacks during exam periods, causing widespread disruption to internet access and online resources for students and faculty. The attacks, which forced Rutgers to spend millions on cybersecurity upgrades, were as much a statement of defiance as they were a demonstration of Jha’s technical prowess.<br><br>Mirai’s release as open-source code in September 2016 marked a turning point. By publishing the malware online, Jha and his collaborators sought to obscure their involvement and create plausible deniability. Instead, they unleashed a tool that hackers worldwide quickly adapted for their own purposes. Within weeks, new variants of Mirai were used to launch attacks against organizations, governments, and even entire countries. The widespread availability of Mirai democratized the ability to conduct large-scale DDoS attacks, amplifying the chaos it could cause.<br><br>Brian Krebs, the cybersecurity journalist whose site was knocked offline by Mirai, described Jha as emblematic of a generation raised on games like Minecraft, where building, breaking, and experimenting were second nature. “The game is brilliant in a lot of ways,” Krebs noted, “but it also teaches you how to think about systems in ways that aren’t always positive.” Jha’s path—from Minecraft devotee to architect of one of the largest botnets in history—demonstrates both the power and the danger of technical expertise developed in an unregulated environment.<br><br>Ultimately, Jha’s actions caught up with him. After an extensive investigation, he and his collaborators pleaded guilty to charges of conspiracy to violate the Computer Fraud and Abuse Act. While Jha avoided prison time in exchange for cooperating with federal authorities, the damage caused by Mirai and its variants continues to ripple across the internet.<br><br>Jha’s story highlights a fundamental truth about the digital world: the same skills that empower creativity and innovation can also enable exploitation and destruction. What began as a way to dominate a Minecraft server grew into a global lesson about the consequences of unchecked ambition in an interconnected world.<h3>Graham Clark - Social Engineer</h3>While Paras Jha weaponized his coding expertise to create one of the most devastating botnets in history, Graham Ivan Clark—known in gaming and hacking circles as “Open” or “OpenHCF”—epitomizes the archetype of the manipulative social engineer. Unlike Jha’s technical precision, Clark’s rise in the digital underworld was fueled by his charisma, psychological acumen, and an unrelenting pursuit of wealth. His journey from scamming Minecraft players to orchestrating one of the most infamous Twitter hacks of all time is both a cautionary tale and a disturbing reminder of the power dynamics that shape online communities.<br><br>Clark’s story begins in the chaotic world of Minecraft Hardcore Factions (HCF), a highly competitive game mode notorious for fostering toxic behavior. By the age of 10, Clark had already built a reputation as a cunning player, manipulating others to gain resources and power. He would promise to sell in-game items like rare capes or coveted OG usernames, only to vanish after receiving payment. As his reputation grew, so did his audacity. Former peers recount how Clark’s charm masked a ruthless streak: he could convince others to help him build his scams, only to leave them burned and humiliated. One of his accomplices described Clark’s attitude as a combination of greed and detachment—he was unbothered by the fallout of his actions.<br><br>This toxic environment wasn’t just a backdrop; it was a training ground. HCF players engaged in activities like doxxing, DDoS attacks, and swatting, which blurred the lines between online mischief and criminal behavior. For Clark, this world was a gateway to broader schemes. By 2016, his exploits extended to OGUsers, a forum where stolen social media accounts and rare usernames were bought and sold. The username “Open,” which he used in Minecraft and hacking communities, likely originated from these markets, where he refined his skills in social engineering. Unlike hacking tools, which require technical expertise, social engineering is a psychological game. Clark excelled at this, manipulating people into giving up credentials or access under false pretenses.<br><br>At just 15, Clark transitioned from Minecraft scams to SIM-swapping, a more lucrative and dangerous form of cybercrime. By exploiting weaknesses in phone carrier systems, Clark and his accomplices could hijack victims’ phone numbers, reset passwords, and drain cryptocurrency wallets. In 2019, he executed a SIM-swap attack that netted him $856,000 worth of Bitcoin from a Seattle tech investor. While authorities eventually linked him to the crime, Clark avoided formal charges by returning part of the stolen funds. This brush with law enforcement seemed to embolden him rather than deter him.<br><br>Clark’s most infamous exploit came in July 2020, when he orchestrated the Twitter hack that compromised accounts of high-profile figures, including Barack Obama, Elon Musk, and Bill Gates. Posing as an IT employee, Clark accessed Twitter’s internal systems via a phishing scheme targeting employees working remotely during the COVID-19 pandemic. Once inside, he hijacked celebrity accounts to post a Bitcoin-doubling scam, earning $117,000 in cryptocurrency. This figure paled in comparison to his previous exploits, but the hack’s audacity made it the biggest security breach in Twitter’s history. At the time of his arrest, authorities discovered Clark had an additional $3 million in Bitcoin, likely accumulated through years of fraud.<br><br>Clark’s ability to navigate online spaces with ease was a testament to his adaptability and cunning. He wasn’t just a scammer; he was a product of the digital culture that shaped him. The HCF community had normalized behaviors like account theft and harassment, framing them as clever tactics rather than moral failures. By the time Clark moved on to more sophisticated crimes, he had already built a network of accomplices and a reputation as a skilled manipulator.<br><br>Yet, his story is also a tale of hubris. Clark’s boldness, flaunted wealth, and disregard for consequences made him a target. After the Twitter hack, his co-conspirators—many of whom were recruited from OGUsers—quickly turned on him, accusing him of greed and withholding stolen funds. The FBI arrested him just weeks after the hack, charging him with 30 felonies, including wire fraud and identity theft. Due to his juvenile status, Clark struck a plea deal, serving only six years under Florida’s youthful offender law.<br><br>The rise and fall of Graham Ivan Clark illuminate the dark underbelly of online gaming and hacking cultures. From Minecraft scams to multi-million-dollar cryptocurrency thefts, Clark’s journey reveals how toxic environments can incubate criminal talent and how digital anonymity can foster a detachment from ethical considerations. His story serves as a stark reminder of the societal risks posed by these insular, exploitative communities—and the need to address the conditions that allow them to thrive.<h3>Aspartame - Hacker</h3>Aspertaine’s name became synonymous with terror in the Minecraft HCF (Hardcore Factions) community, a realm already infamous for its cutthroat culture and toxic dynamics. What began as in-game trolling and petty scams quickly evolved into a pattern of harassment and abuse so extreme that it left a trail of fear far beyond the confines of the virtual world.<br><br>At first, Aspartame was a nuisance—one of countless players who blurred the line between competition and cruelty. His early antics, which included hacking accounts and leaking personal information, were a common feature of the HCF landscape. But Aspertaine’s appetite for power and control soon outgrew the game itself. He began compiling databases of personal information, leveraging doxxing bots to pull private details about anyone who crossed his path. For him, it wasn’t just about winning; it was about destruction.<br><br>His favorite weapon of choice was swatting. With a single call, he could turn someone’s home into a scene of chaos, sending armed police to respond to fabricated emergencies. One victim recalled watching from a window as their house was surrounded by SWAT officers, guns drawn, after a false report claimed there had been a murder inside. Another family endured hours of interrogation because Aspartame had hacked their Ring doorbell, taunting them with threats while they listened in terror. Over the course of one week, he orchestrated swatting attacks across twelve states, terrorizing families who had no connection to his online world.<br><br>These weren’t isolated incidents; they were a pattern. In one particularly harrowing case, a school received a bomb threat that prompted a full evacuation. The call wasn’t random—it was part of Aspertaine’s systematic campaign to destroy the lives of those who had the misfortune of crossing him. He didn’t just want to scare his victims; he wanted them to feel utterly powerless. For Aspartame, this was a sport.<br><br>But his cruelty didn’t stop with swatting. Perhaps the most disturbing aspect of Aspertaine’s behavior was his exploitation of young girls. Using the personal information he had collected, he extorted them into sending degrading photos of themselves—known as “fan signs”—to prove their submission. For many victims, this wasn’t just an invasion of privacy; it was a deeply traumatic experience that drove them offline or left them isolated and afraid.<br><br>Aspartame bragged openly about these extortions, inviting others to join his twisted games. In one group chat, he coerced a 13-year-old boy into writing his name on his face, threatening to call in a bomb threat to the boy’s school if he refused. He leveraged his power in Discord servers, creating bots capable of pulling detailed personal information on players with a single command. The fear he inspired was so pervasive that even seasoned hackers hesitated to challenge him.<br><br>The culture of the HCF community, with its unchecked toxicity and emphasis on power, provided fertile ground for Aspertaine’s rise. Server administrators, well aware of his reputation, often turned a blind eye or even collaborated with him. On one server, he paid for administrative privileges, which he used to manipulate and harass players. On another, he blackmailed staff into lifting bans against him, threatening to leak their personal information if they didn’t comply.<br><br>Eventually, Aspertaine’s actions drew the attention of law enforcement. A series of bomb threats and swatting incidents triggered an FBI investigation, culminating in his arrest in 2022. Despite wiping his computer before authorities arrived, his trail of crimes was too extensive to conceal. He ultimately pleaded guilty to multiple charges, including identity theft and conspiracy, and was sentenced to seven years in prison.<br><br>Even now, the fear he sowed lingers. His victims—some as young as 13—continue to grapple with the trauma he inflicted. Families upended by swatting incidents recall the nights they spent in terror, wondering if they would survive. And yet, Aspertaine’s story is more than just a cautionary tale about one individual’s descent into cruelty. It’s a reflection of a digital culture that too often rewards the worst behaviors, a warning about what can happen when communities prioritize power over accountability.<h3>Conclusion:</h3>Through these stories, I hoped to offer a clearer understanding of the Hardcore Factions (HCF) community and its peculiar evolution into a breeding ground for cybercrime and illicit activity. While no singular explanation can account for why this gamemode attracted so many individuals who turned to criminality, my own experience suggests that it fostered a \"frat-like\" brotherhood. This bond could be both empowering and destructive, creating a sense of shared identity that often blurred the lines between camaraderie and complicity.<br><br>Looking at this through the framework of this class, I seek to  illustrate how unregulated digital spaces and communities can evolve into powerful, yet often destructive, ecosystems. HCF and similar subcultures thrive on the misuse of data, anonymity, and exploitation of trust, creating environments where digital tools can be weaponized in ways their creators never intended. These spaces are microcosms of larger discussions about the ethical dimensions of data and technology, emphasizing how the lack of oversight and accountability can lead to unforeseen consequences.<br><br>The relevance of examining these stories lies in its ability to highlight the unintended intersections of technology, behavior, and community dynamics. These stories force us to grapple with the dual-edged nature of digital innovation: the same tools that empower can also be used to exploit. Understanding how these ecosystems operate is essential for addressing the broader societal implications of data and technology in our lives. Ultimately, the story of HCF is a cautionary tale—a reminder of the potential for technology to shape our futures in unexpected ways, for better or worse.<br><br>",
              "images": [
                {
                  "url": "/images/ANON_FINAL.png",
                  "caption": "An illustrative image",
                  "alt_text": "Image showing zine artwork"
                }
              ]
            }
          }
        ]
      }
    }
  }
}
