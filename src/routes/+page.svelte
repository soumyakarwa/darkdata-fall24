<script>
</script>

<svelte:head>
	<title>Dark Data Zine: Fall 24</title>
	<meta name="description" content="Svelte demo app" />
</svelte:head>

<section>
	<div class="content-title">A Note From The Editor</div>
	<div class="content">
		Are our phones really listening to us? What happens with our genetic data when the company we entrusted it with goes bankrupt? How can we protect children from AI chatbots? Does “the Algorithm” know us better than we know ourselves? This semester, through Professor David Carroll’s “Dark Data” course taught at Parsons School of Design, The New School, we’ve tackled a myriad of questions emerging from conspiracy theories, grave concerns, and philosophical musings.<br><br>

		This past November’s US presidential election, which marked a critical turning point for privacy and data protection in the US, underscores the necessity for engaging with these topics. In 2018, the Cambridge Analytica scandal exposed the 2016 Trump campaign’s use of Facebook user data to microtarget Black Americans and suppress voter turnout during the election. Fast forward to this year, and we witness history repeating itself with the Elon Musk-funded Future Coalition PAC microtargeting Muslim and Jewish voters to deliver conflicting messages. These recurring tactics across campaign cycles showcase the cyclical nature of unethical data practices and their implications for democracy.<br><br>

		With the impending threat of increased surveillance and an escalation of privacy invasions under Trump’s proposed Project 2025, understanding the landscape of these issues, both domestically and globally, has become ever more crucial. How will US surveillance and data privacy frameworks morph in the wake of the administration handover? What lessons can be taken from other countries’ surveillance and privacy practices like those of India, China, and Europe?<br><br>

		Against this backdrop, our zine presents eight projects developed as part of the “Dark Data” course. Drawing inspiration from course material, these projects investigate critical topics from surveillance and the media to the misuse of digital technology, and from gendered AI harms to missing data sets. Collectively, through these individual explorations, we hope to paint a broader picture of the “Dark Data” landscape.<br><br>

		While the onus for safeguarding personal data should not exclusively be placed on consumers, we’ve witnessed, time and time again, that legislation often lags behind technological advancements. This dynamic has played out repeatedly this past year, and the consequences have been devastating. The tragic death of a 14-year-old boy using Character AI—a platform for creating AI-powered virtual friends—prompted the company to rush to implement child safety measures. Similarly, DeepFake child pornography has swirled through school hallways worldwide while administrators have scrambled to update school policies. Though social media platforms like Instagram have recently introduced new restrictions for users under 18, these efforts still leave users bearing much of the burden to protect themselves.<br><br>

		Admittedly, these challenges can feel overwhelming and disheartening, but awareness is the first step towards affecting change. While legislation does not happen overnight, through this zine, we hope to empower readers to engage with "Dark Data" topics through shedding light on these pressing issues.<br><br>

		Ariel Calver,<br>
		MFA Design and Technology 2025	

	</div>
</section>

<style>
	section {
		padding-top: var(--gap); 
		display: flex;
		flex-direction: column;
		justify-content: center;
		align-items: center;
		/* max-width: 80%;  */
	}
</style>
